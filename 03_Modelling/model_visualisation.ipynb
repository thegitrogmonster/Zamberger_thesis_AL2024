{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code written herein aims to generate clean plots to include in the thesis. \n",
    "\n",
    "The plots created during the modelling and AL processes contain technical intresting information, but are not always suitable for the thesis. \n",
    "Therefor selected plots are recreated here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"20\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"20\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"20\"\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"20\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.kernel_ridge import KernelRidge as KRR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basepath\n",
    "basepath = \"../\"  # Project directory\n",
    "sys.path.append(basepath)\n",
    "\n",
    "# Data\n",
    "DATA_PATH = basepath + \"data\"\n",
    "\n",
    "# Results path\n",
    "RESULTS_PATH = basepath + \"03_Modelling/03_1_rscv/rscv_results/\"\n",
    "\n",
    "# Figure path\n",
    "FIGURE_PATH = basepath + \"03_Modelling/03_1_rscv/rscv_figures/\"\n",
    "\n",
    "# Path to environment\n",
    "ENV_PATH = \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib\"\n",
    "\n",
    "# Modelpath\n",
    "MODEL_PATH = basepath + \"models\"\n",
    "\n",
    "# Logging\n",
    "LOG_DIR = basepath + \"03_Modelling/03_1_rscv/\"\n",
    "\n",
    "# Active Learning library\n",
    "AL_PATH = basepath + \"al_lib\"\n",
    "\n",
    "# Add the paths\n",
    "sys.path.extend(\n",
    "    {DATA_PATH, FIGURE_PATH, ENV_PATH, MODEL_PATH, RESULTS_PATH, LOG_DIR, AL_PATH}\n",
    ")\n",
    "sys.path  # Check if the path is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dps_deriv_1200 = pd.read_csv(\n",
    "    DATA_PATH + \"/dpsDeriv1200.csv\", sep=\",\", decimal=\".\", encoding=\"utf-8\"\n",
    ")\n",
    "data_dps_deriv_1200 = data_dps_deriv_1200.rename(columns=lambda x: x.replace(\"X\", \"\"))\n",
    "data_dps_deriv_1200 = data_dps_deriv_1200.rename(columns={\"Unnamed: 0\": \"Samplename\"})\n",
    "data_dps_deriv_1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch for the dataset\n",
    "# Select from (data_small, data_full, data_2nd_deriv) or other if implemented\n",
    "data_raw = data_dps_deriv_1200\n",
    "data_raw.dataset_name = \"data_dps_deriv_1200\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for the CV\n",
    "\n",
    "# Switch for testing mode (use only 10% of the data, among others)\n",
    "testing = False\n",
    "\n",
    "# Define a random state for randomized processes\n",
    "random_state = np.random.RandomState(202375)\n",
    "\n",
    "if testing == True:\n",
    "    nfolds = 5\n",
    "    NoTrials = 5\n",
    "    n_jobs = 20\n",
    "    save_model = False\n",
    "    # data = data_raw.sample(frac=0.15, random_state=random_state)\n",
    "    data = data_raw\n",
    "\n",
    "else:\n",
    "    nfolds = 10\n",
    "    NoTrials = 15\n",
    "    n_jobs = 30\n",
    "    save_model = True\n",
    "    data = data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "import warnings\n",
    "\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.exceptions import FitFailedWarning\n",
    "\n",
    "# Turn of sklearn warnings for failed fits \n",
    "if testing == True: \n",
    "    simplefilter(\"ignore\", category=FitFailedWarning)\n",
    "    simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "    warnings.filterwarnings(\n",
    "    \"ignore\", message=\".*y residual is constant*.\", category=UserWarning, append=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into target and features\n",
    "# The goal is to predict the year column of the dataset using the spectral data\n",
    "X = data.select_dtypes(\"float\")\n",
    "y = data[\"year\"]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "test_size = 0.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=random_state\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "# assert the shapes and raise an error if they are not equal\n",
    "assert X_train.shape[0] + X_test.shape[0] == X.shape[0]\n",
    "assert y_train.shape[0] + y_test.shape[0] == y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "# create a scorer which calculates Root Mean Squeared Error (RMSE)\n",
    "\n",
    "scoring = make_scorer(root_mean_squared_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual-vs-Predicted plot for the best model\n",
    "\n",
    "# generate the actual vs. predicted plot\n",
    "from al_lib.helper_functions import plot_actual_vs_pred\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf_rscv_results_file = f\"{RESULTS_PATH}rf_rscv_results.csv\"\n",
    "\n",
    "# import the optimal model parameters\n",
    "rf_results = pd.read_csv(rf_rscv_results_file)\n",
    "# select the model parameters with the lowest RMSE\n",
    "optimal_params_str_rf = rf_results.loc[rf_results[\"RMSE\"].idxmin(), \"params\"]\n",
    "optimal_params_rf = dict(eval(optimal_params_str_rf))\n",
    "\n",
    "rf_opt = RandomForestRegressor(**optimal_params_rf, random_state=random_state)\n",
    "\n",
    "y_pred_rf = rf_opt.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "title_str = (\n",
    "    f\"Actual vs. Predicted Values (Random Forests)\"\n",
    "    + f\"\\n RMSE = {root_mean_squared_error(y_test, y_pred_rf):.2f}\"\n",
    ")\n",
    "\n",
    "param_dict = {\"title\": title_str}\n",
    "fig_path = f\"{FIGURE_PATH}avp_rf_rscv.png\"\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(8, 6)\n",
    "rf_avp_plot = plot_actual_vs_pred(ax, y_test, y_pred_rf, param_dict, fig_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cross_decomposition\n",
    "\n",
    "pls = cross_decomposition.PLSRegression()\n",
    "pls_rscv_results_file = f\"{RESULTS_PATH}/pls_rscv_results.csv\"\n",
    "\n",
    "# generate the actual vs. predicted plot\n",
    "from al_lib.helper_functions import plot_actual_vs_pred\n",
    "\n",
    "# import the optimal model parameters\n",
    "pls_results = pd.read_csv(pls_rscv_results_file)\n",
    "# select the model parameters with the lowest RMSE\n",
    "optimal_params_str_pls = pls_results.loc[pls_results[\"RMSE\"].idxmin(), \"params\"]\n",
    "optimal_params_pls = dict(eval(optimal_params_str_pls))\n",
    "# fit the data with the optimal model parameters\n",
    "pls_opt = cross_decomposition.PLSRegression(**optimal_params_pls)\n",
    "\n",
    "y_pred_pls = pls_opt.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "# plot\n",
    "title_str = (\n",
    "    f\"Actual vs. Predicted Values (PLS)\"\n",
    "    + f\"\\n RMSE = {np.sqrt(mean_squared_error(y_test, y_pred_pls)):.2f}\"\n",
    ")\n",
    "\n",
    "param_dict = {\"title\": title_str}\n",
    "fig_path = (f\"{FIGURE_PATH}/avp_pls_rscv.png\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(8, 6)\n",
    "pls_avp_plot = plot_actual_vs_pred(ax, y_test, y_pred_pls, param_dict, fig_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge as KRR\n",
    "\n",
    "krr = KRR()\n",
    "krr_rscv_results_file = f\"{RESULTS_PATH}/krr_rscv_results.csv\"\n",
    "\n",
    "\n",
    "# generate the actual vs. predicted plot\n",
    "\n",
    "# import the optimal model parameters\n",
    "krr_results = pd.read_csv(krr_rscv_results_file)\n",
    "\n",
    "# select the model parameters with the lowest RMSE\n",
    "optimal_params_str_krr = krr_results.loc[krr_results[\"RMSE\"].idxmin(), \"params\"]\n",
    "optimal_params_krr = dict(eval(optimal_params_str_krr))\n",
    "krr_opt = KRR(**optimal_params_krr)\n",
    "\n",
    "y_pred_krr = krr_opt.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "# plot\n",
    "\n",
    "# break the optimal_params_str_krr string into more lines\n",
    "\n",
    "title_str = (\n",
    "    f\"Actual vs. Predicted Values (KRR)\"\n",
    "    + f\"\\n RMSE = {np.sqrt(mean_squared_error(y_test, y_pred_krr)):.2f}\"\n",
    ")\n",
    "\n",
    "param_dict = {\"title\": title_str}\n",
    "fig_path_krr = (f\"{FIGURE_PATH}/avp_krr_rscv.png\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(8, 6)\n",
    "krr_avp_plot = plot_actual_vs_pred(ax, y_test, y_pred_krr, param_dict, fig_path_krr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mlp\n",
    "from sklearn.neural_network import MLPRegressor as MLP\n",
    "\n",
    "mlp = MLP()\n",
    "mlp_rscv_results_file = f\"{RESULTS_PATH}/mlp_rscv_results.csv\"\n",
    "\n",
    "# generate the actual vs. predicted plot\n",
    "\n",
    "# import the optimal model parameters\n",
    "mlp_results = pd.read_csv(mlp_rscv_results_file)\n",
    "\n",
    "# select the (optimal) model parameters with the lowest RMSE\n",
    "optimal_params_str_mlp = mlp_results.loc[mlp_results[\"RMSE\"].idxmin(), \"params\"]\n",
    "optimal_params_mlp = dict(eval(optimal_params_str_mlp))\n",
    "\n",
    "# fit the data with the optimal model parameters\n",
    "mlp_opt = MLP(**optimal_params_mlp, random_state=random_state)\n",
    "\n",
    "y_pred_mlp = mlp_opt.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "# plot\n",
    "\n",
    "# break the optimal_params_str_mlp string into more lines\n",
    "optimal_params_str_mlp_break = optimal_params_str_mlp.replace(\", \", \",\\n\")\n",
    "\n",
    "title_str = (\n",
    "    f\"Actual vs. Predicted Values (MLP)\"\n",
    "    + f\"\\n RMSE = {np.sqrt(mean_squared_error(y_test, y_pred_mlp)):.2f}\"\n",
    ")\n",
    "\n",
    "param_dict = {\"title\": title_str}\n",
    "fig_path_mlp = (f\"{FIGURE_PATH}/avp_mlp_rscv.png\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(8, 6)\n",
    "mlp_avp_plot = plot_actual_vs_pred(ax, y_test, y_pred_mlp, param_dict, fig_path_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb = XGBRegressor()\n",
    "xgb_rscv_results_file = f\"{RESULTS_PATH}/xgb_rscv_results.csv\"\n",
    "\n",
    "# import the optimal model parameters\n",
    "xgb_results = pd.read_csv(xgb_rscv_results_file)\n",
    "\n",
    "# round the results to 4 decimal places\n",
    "xgb_results = xgb_results.round(4)\n",
    "\n",
    "# select the model parameters with the lowest RMSE\n",
    "optimal_params_str_xgb = xgb_results.loc[xgb_results[\"RMSE\"].idxmin(), \"params\"]\n",
    "optimal_params_xgb = dict(eval(optimal_params_str_xgb))\n",
    "\n",
    "# fit the data with the optimal model parameters\n",
    "xgb_opt = XGBRegressor(**optimal_params_xgb, random_state=random_state)\n",
    "\n",
    "y_pred_xgb = xgb_opt.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "# plot\n",
    "from al_lib.helper_functions import plot_actual_vs_pred\n",
    "\n",
    "# break the optimal_params_str_ string into more lines\n",
    "optimal_params_str_xgb_break = optimal_params_str_xgb.replace(\", \", \",\\n\")\n",
    "\n",
    "title_str = (\n",
    "    f\"Actual vs. Predicted Values(XGBoost)\"\n",
    "    + f\"\\n RMSE = {np.sqrt(mean_squared_error(y_test, y_pred_xgb)):.2f}\"\n",
    ")\n",
    "\n",
    "param_dict = {\"title\": title_str}\n",
    "fig_path = (f\"{FIGURE_PATH}/avp_xgb_rscv.png\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(8, 6)\n",
    "xgb_avp_plot = plot_actual_vs_pred(ax, y_test, y_pred_xgb, param_dict, fig_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HGB\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor as HGB\n",
    "\n",
    "hbg = HGB()\n",
    "hgb_rscv_results_file = f\"{RESULTS_PATH}/hgb_rscv_results.csv\"\n",
    "\n",
    "# generate the actual vs. predicted plot\n",
    "hgb_results = pd.read_csv(hgb_rscv_results_file)\n",
    "\n",
    "# select the model parameters with the lowest RMSE\n",
    "# select the model parameters with the lowest RMSE\n",
    "optimal_params_str_hgb = hgb_results.loc[hgb_results[\"RMSE\"].idxmin(), \"params\"]\n",
    "optimal_params_hgb = dict(eval(optimal_params_str_hgb))\n",
    "\n",
    "# fit the data with the optimal model parameters\n",
    "hgb_opt = HGB(**optimal_params_hgb, random_state=random_state)\n",
    "\n",
    "y_pred_hgb = hgb_opt.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "# plot\n",
    "\n",
    "# break the optimal_params_str_ string into more lines\n",
    "optimal_params_str_hgb_break = optimal_params_str_hgb.replace(\", \", \",\\n\")\n",
    "\n",
    "\n",
    "title_str = (\n",
    "    f\"Actual vs. Predicted Values (HGB)\"\n",
    "    + f\"\\n RMSE = {root_mean_squared_error(y_test, y_pred_hgb):.2f}\"\n",
    ")\n",
    "fig_path = (f\"{FIGURE_PATH}/avp_hgb_rscv.png\")\n",
    "param_dict = {\"title\": title_str}\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(8, 6)\n",
    "xgb_avp_plot = plot_actual_vs_pred(ax, y_test, y_pred_xgb, param_dict, fig_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation (RSCV)\n",
    "Documentation of the optimal params of the RSCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the results to a csv file\n",
    "\n",
    "rscv_documentation_df =  pd.DataFrame(\n",
    "    {\n",
    "        \"Model\": [\n",
    "            \"Random Forest\",\n",
    "            \"PLS\",\n",
    "            \"Kernel Ridge\",\n",
    "            \"XGBoost\",\n",
    "            \"HistGradientBoosting\",\n",
    "        ],\n",
    "        \"RMSE\": [\n",
    "            round(np.sqrt(mean_squared_error(y_test, y_pred_rf)),2),\n",
    "            round(np.sqrt(mean_squared_error(y_test, y_pred_pls)),2),\n",
    "            round(np.sqrt(mean_squared_error(y_test, y_pred_krr)),2),\n",
    "            round(np.sqrt(mean_squared_error(y_test, y_pred_xgb)),2),\n",
    "            round(np.sqrt(mean_squared_error(y_test, y_pred_hgb)),2)\n",
    "        ],\n",
    "        \"hyperparameters\": [\n",
    "            optimal_params_str_rf,\n",
    "            optimal_params_str_pls,\n",
    "            optimal_params_str_krr,\n",
    "            optimal_params_str_xgb,\n",
    "            optimal_params_str_hgb,\n",
    "        ],\n",
    "    })\n",
    "# write the results to a csv file\n",
    "rscv_documentation_df.to_csv(f\"{RESULTS_PATH}/rscv_documentation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSCV - results\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results path\n",
    "RESULTS_PATH = basepath + \"03_Modelling/03_2_gscv/gscv_results/\"\n",
    "\n",
    "# Figure path\n",
    "FIGURE_PATH = basepath + \"03_Modelling/03_2_gscv/gscv_figures/\"\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.kernel_ridge import KernelRidge as KRR\n",
    "from sklearn.neural_network import MLPRegressor as MLP\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor as HGB\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the actual vs. predicted plot\n",
    "from al_lib.helper_functions import plot_actual_vs_pred\n",
    "rf_gscv_results_file = f\"{RESULTS_PATH}rf_gscv_results.csv\"\n",
    "# import the optimal model parameters\n",
    "rf_results = pd.read_csv(rf_gscv_results_file)\n",
    "# select the model parameters with the lowest RMSE\n",
    "optimal_params_str_rf = rf_results.loc[rf_results[\"RMSE\"].idxmin(), \"params\"]\n",
    "optimal_params_rf = dict(eval(optimal_params_str_rf))\n",
    "\n",
    "rf_opt = RandomForestRegressor(**optimal_params_rf, random_state=random_state)\n",
    "\n",
    "y_pred_rf = rf_opt.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "title_str_params = optimal_params_str_rf.replace(\"np.int64\", \"\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "\n",
    "title_str = (\n",
    "    f\"Actual vs. Predicted Values (Random Forests)\"\n",
    "    + f\"\\n RMSE = {root_mean_squared_error(y_test, y_pred_rf):.2f}\"\n",
    ")\n",
    "\n",
    "param_dict = {\"title\": title_str}\n",
    "fig_path = f\"{FIGURE_PATH}avp_rf_gscv.png\"\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(8, 6)\n",
    "rf_avp_plot = plot_actual_vs_pred(ax, y_test, y_pred_rf, param_dict, fig_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pls_gscv_results_file = f\"{RESULTS_PATH}pls_gscv_results.csv\"\n",
    "\n",
    "# import the optimal model parameters\n",
    "pls_results = pd.read_csv(pls_gscv_results_file)\n",
    "# select the model parameters with the lowest RMSE\n",
    "optimal_params_str_pls = pls_results.loc[pls_results[\"RMSE\"].idxmin(), \"params\"]\n",
    "optimal_params_pls = dict(eval(optimal_params_str_pls))\n",
    "\n",
    "pls_opt = PLSRegression(**optimal_params_pls)\n",
    "\n",
    "y_pred_pls = pls_opt.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "title_str_params = optimal_params_str_pls.replace(\"np.int64\", \"\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "\n",
    "title_str = (\n",
    "    f\"PLS Regression: Actual vs. Predicted Values\"\n",
    "    + f\"\\n RMSE = {root_mean_squared_error(y_test, y_pred_pls):.2f}\"\n",
    ")\n",
    "\n",
    "param_dict = {\"title\": title_str}\n",
    "fig_path = f\"{FIGURE_PATH}avp_pls_gscv.png\"\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(8, 6)\n",
    "rf_avp_plot = plot_actual_vs_pred(ax, y_test, y_pred_pls, param_dict, fig_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "krr = KRR()\n",
    "\n",
    "# Define the results file\n",
    "krr_gscv_results_file = f\"{RESULTS_PATH}krr_gscv_results.csv\"\n",
    "\n",
    "# generate the actual vs. predicted plot\n",
    "from al_lib.helper_functions import plot_actual_vs_pred\n",
    "\n",
    "# import the optimal model parameters\n",
    "krr_results = pd.read_csv(krr_gscv_results_file)\n",
    "# select the model parameters with the lowest RMSE\n",
    "optimal_params_str_krr = krr_results.loc[krr_results[\"RMSE\"].idxmin(), \"params\"]\n",
    "optimal_params_krr = dict(eval(optimal_params_str_krr))\n",
    "\n",
    "krr_opt = KRR(**optimal_params_krr)\n",
    "\n",
    "y_pred_krr = krr_opt.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "title_str_params = optimal_params_str_krr.replace(\"np.int64\", \"\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"np.float64\", \"\")\n",
    "\n",
    "title_str = (\n",
    "    f\"Kernel-Ridge Regression: Actual vs. Predicted Values\"\n",
    "    + f\"\\n RMSE = {root_mean_squared_error(y_test, y_pred_krr):.2f}\"\n",
    ")\n",
    "\n",
    "param_dict = {\"title\": title_str}\n",
    "fig_path = f\"{FIGURE_PATH}avp_krr_gscv.png\"\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(8, 6)\n",
    "krr_avp_plot = plot_actual_vs_pred(ax, y_test, y_pred_krr, param_dict, fig_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mlp\n",
    "from sklearn.neural_network import MLPRegressor as MLP\n",
    "mlp = MLP()\n",
    "\n",
    "mlp_gscv_results_file = f\"{RESULTS_PATH}/mlp_gscv_results.csv\"\n",
    "\n",
    "# import parameters\n",
    "mlp_results = pd.read_csv(mlp_gscv_results_file)\n",
    "optimal_params_str_mlp = mlp_results.loc[mlp_results[\"RMSE\"].idxmin(), \"params\"]\n",
    "optimal_params_mlp = dict(eval(optimal_params_str_mlp))\n",
    "\n",
    "mlp_opt = MLP(**optimal_params_mlp, random_state=random_state)\n",
    "\n",
    "y_pred_mlp = mlp_opt.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "title_str_params = optimal_params_str_mlp.replace(\"np.int64\", \"\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"np.float64\", \"\")\n",
    "\n",
    "title_str = (\n",
    "    f\"Actual vs. Predicted Values (MLP)\"\n",
    "    + f\"\\n RMSE = {root_mean_squared_error(y_test, y_pred_mlp):.2f}\"\n",
    ")\n",
    "\n",
    "param_dict = {\"title\": title_str}\n",
    "fig_path = f\"{FIGURE_PATH}avp_mlp_gscv.png\"\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(8, 6)\n",
    "mlp_avp_plot = plot_actual_vs_pred(ax, y_test, y_pred_mlp, param_dict, fig_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation (GSCV)\n",
    "Documentation of the optimal params of the GSCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gscv_documentation_df =  pd.DataFrame(\n",
    "    {\n",
    "        \"Model\": [\n",
    "            \"Random Forest\",\n",
    "            \"PLS\",\n",
    "            \"Kernel Ridge\",\n",
    "\n",
    "        ],\n",
    "        \"RMSE\": [\n",
    "            round(np.sqrt(mean_squared_error(y_test, y_pred_rf)), 2),\n",
    "            round(np.sqrt(mean_squared_error(y_test, y_pred_pls)), 2),\n",
    "            round(np.sqrt(mean_squared_error(y_test, y_pred_krr)), 2),\n",
    "\n",
    "        ],\n",
    "        \"hyperparameters\": [\n",
    "            optimal_params_str_rf,\n",
    "            optimal_params_str_pls,\n",
    "            optimal_params_str_krr,\n",
    "\n",
    "        ],\n",
    "    })\n",
    "# write the results to a csv file\n",
    "gscv_documentation_df.to_csv(f\"{RESULTS_PATH}/gscv_documentation.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
