{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of the Initial Model \n",
    "\n",
    "## Introduction\n",
    "\n",
    "This Notebook is develped to identify and specify the models, which will be used to apply the Active Learning strategies on. At least two models will be created, as described in the initial Research Proposal: \n",
    "1. PLS-Regression-Model \n",
    "2. Random-Forest-Regression-Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preperation\n",
    "\n",
    "To work in python, various libraries are needed. So the neccessary libraries are imported in the next cell. \n",
    "\n",
    "The code is developed inspired by the machine learining course by [Peter Sykacek](peter.sykacek[at]boku.ac.at) in the winter of 2023.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python312.zip',\n",
       " '/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12',\n",
       " '/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/lib-dynload',\n",
       " '',\n",
       " '/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages',\n",
       " './',\n",
       " './server_files/ml_group/course.lib',\n",
       " './data',\n",
       " '/home/fhwn.ac.at/202375/.conda/envs/thesis/lib',\n",
       " './models',\n",
       " './figures/03_modeling_figures',\n",
       " './results/03_modeling_results']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "# sys.path.clear()\n",
    "\n",
    "# Basepath\n",
    "basepath=\"./\" # Project directory\n",
    "sys.path.append(basepath)\n",
    "sys.path.append(basepath+\"server_files/ml_group/course.lib\")\n",
    "\n",
    "# Data\n",
    "DATA_PATH = basepath + \"data\"\n",
    "\n",
    "#Figure\n",
    "FIGURE_PATH = basepath + \"figures/03_modeling_figures\"\n",
    "\n",
    "# Modelpath\n",
    "MODEL_PATH = basepath + \"models\"\n",
    "\n",
    "# Path to environment\n",
    "\n",
    "ENV_PATH = \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib\"\n",
    "\n",
    "# Resultspath\n",
    "RESULTS_PATH = basepath + \"results/03_modeling_results\"\n",
    "\n",
    "# Add the paths\n",
    "sys.path.extend({DATA_PATH, FIGURE_PATH, MODEL_PATH, ENV_PATH, RESULTS_PATH})\n",
    "sys.path # Check if the path is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## timing the full notebook\n",
    "import time\n",
    "nb_start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Path to store the ML Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Define the path to save the ml models\n",
    "\n",
    "MODEL_PATH = basepath + \"models\"\n",
    "sys.path.append(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ml_lib as mlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### turn off convergence warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "import os\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Model functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate various models an import of the respective functions from preexisting packages is neccessary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch Crossvalidation\n",
    "\n",
    "[sklearn GSCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV)\n",
    "\n",
    "Exhaustive search over specified parameter values for an estimator.\n",
    "Important members are fit, predict.\n",
    "\n",
    "* GridSearchCV implements a \"fit\" and a \"score\" method.\n",
    "* It also implements \"score_samples\", \"predict\", \"predict_proba\", \"decision_function\", \"transform\" and \"inverse_transform\" if they are implemented in the estimator used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV as GSCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Parameter Optimization\n",
    "\n",
    "[sklearn RandomizedSearchCV](https://scikit-learn.org/stable/modules/grid_search.html#grid-search)  \n",
    "\n",
    " RandomizedSearchCV implements a randomized search over parameters, where each setting is sampled from a distribution over possible parameter values. This has two main benefits over an exhaustive search:\n",
    "\n",
    "A budget can be chosen independent of the number of parameters and possible values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold cross-validator.\n",
    "[sklearn KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold)\n",
    "\n",
    "Provides train/test indices to split data in train/test sets. Split dataset into k consecutive folds (without shuffling by default).\n",
    "\n",
    "Each fold is then used once as a validation while the k - 1 remaining folds form the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Ridge\n",
    "\n",
    "[sklearn KRR](https://scikit-learn.org/stable/modules/kernel_ridge.html#kernel-ridge-regression)\n",
    "\n",
    "Kernel ridge regression (KRR) [M2012] combines Ridge regression and classification (linear least squares with l2-norm regularization) with the kernel trick. It thus learns a linear function in the space induced by the respective kernel and the data. For non-linear kernels, this corresponds to a non-linear function in the original space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge as KRR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Inspection\n",
    "\n",
    "[sklearn cv_results_](https://scikit-learn.org/stable/modules/grid_search.html#analyzing-results-with-the-cv-results-attribute)\n",
    "\n",
    "\"The cv_results_ attribute contains useful information for analyzing the results of a search. It can be converted to a pandas dataframe with df = pd.DataFrame(est.cv_results_).\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section the sample data will be imported. \n",
    "\n",
    "Currently 2 Datasets are of interest for us: \n",
    "1. PS20191107_gegl.csv\n",
    "2. dps1200.csv\n",
    "\n",
    "The differences are that the first is a dataframe containing the data unmodified and full. It was used to generate the later, which contains only selected sections of the spectra. The Wavelengths of this dataset were selected by discarding Wavelengths, based on critieria ???\n",
    "\n",
    "**TODO**: Research the criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PS20191107 (Full Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>year</th>\n",
       "      <th>Origin</th>\n",
       "      <th>type</th>\n",
       "      <th>3996</th>\n",
       "      <th>3994</th>\n",
       "      <th>3992</th>\n",
       "      <th>3990</th>\n",
       "      <th>3988</th>\n",
       "      <th>3987</th>\n",
       "      <th>...</th>\n",
       "      <th>417</th>\n",
       "      <th>415</th>\n",
       "      <th>413</th>\n",
       "      <th>411</th>\n",
       "      <th>409</th>\n",
       "      <th>407</th>\n",
       "      <th>405</th>\n",
       "      <th>403</th>\n",
       "      <th>401</th>\n",
       "      <th>399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2GOS-18_1955</td>\n",
       "      <td>1955</td>\n",
       "      <td>POL</td>\n",
       "      <td>living</td>\n",
       "      <td>0.016119</td>\n",
       "      <td>0.015972</td>\n",
       "      <td>0.015830</td>\n",
       "      <td>0.015728</td>\n",
       "      <td>0.015734</td>\n",
       "      <td>0.015787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027973</td>\n",
       "      <td>-0.028180</td>\n",
       "      <td>-0.028389</td>\n",
       "      <td>-0.028595</td>\n",
       "      <td>-0.029011</td>\n",
       "      <td>-0.029123</td>\n",
       "      <td>-0.029323</td>\n",
       "      <td>-0.029610</td>\n",
       "      <td>-0.029759</td>\n",
       "      <td>-0.029746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2GOS-18_1969</td>\n",
       "      <td>1969</td>\n",
       "      <td>POL</td>\n",
       "      <td>living</td>\n",
       "      <td>0.016368</td>\n",
       "      <td>0.016543</td>\n",
       "      <td>0.016663</td>\n",
       "      <td>0.016569</td>\n",
       "      <td>0.016333</td>\n",
       "      <td>0.016217</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029520</td>\n",
       "      <td>-0.029747</td>\n",
       "      <td>-0.029978</td>\n",
       "      <td>-0.030204</td>\n",
       "      <td>-0.030087</td>\n",
       "      <td>-0.030284</td>\n",
       "      <td>-0.030746</td>\n",
       "      <td>-0.031163</td>\n",
       "      <td>-0.031519</td>\n",
       "      <td>-0.031815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2GOS-18_1974</td>\n",
       "      <td>1974</td>\n",
       "      <td>POL</td>\n",
       "      <td>living</td>\n",
       "      <td>0.021364</td>\n",
       "      <td>0.021662</td>\n",
       "      <td>0.021862</td>\n",
       "      <td>0.021573</td>\n",
       "      <td>0.020925</td>\n",
       "      <td>0.020585</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031046</td>\n",
       "      <td>-0.031270</td>\n",
       "      <td>-0.031483</td>\n",
       "      <td>-0.031701</td>\n",
       "      <td>-0.032089</td>\n",
       "      <td>-0.032390</td>\n",
       "      <td>-0.032609</td>\n",
       "      <td>-0.032653</td>\n",
       "      <td>-0.032627</td>\n",
       "      <td>-0.032784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2GOS-18_1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>POL</td>\n",
       "      <td>living</td>\n",
       "      <td>0.019351</td>\n",
       "      <td>0.019246</td>\n",
       "      <td>0.019181</td>\n",
       "      <td>0.018998</td>\n",
       "      <td>0.018926</td>\n",
       "      <td>0.019205</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029852</td>\n",
       "      <td>-0.030092</td>\n",
       "      <td>-0.030361</td>\n",
       "      <td>-0.030647</td>\n",
       "      <td>-0.031115</td>\n",
       "      <td>-0.031281</td>\n",
       "      <td>-0.031376</td>\n",
       "      <td>-0.031721</td>\n",
       "      <td>-0.032172</td>\n",
       "      <td>-0.032433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2GOS-18_1996</td>\n",
       "      <td>1996</td>\n",
       "      <td>POL</td>\n",
       "      <td>living</td>\n",
       "      <td>0.018548</td>\n",
       "      <td>0.018604</td>\n",
       "      <td>0.018670</td>\n",
       "      <td>0.018616</td>\n",
       "      <td>0.018375</td>\n",
       "      <td>0.018266</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029963</td>\n",
       "      <td>-0.030206</td>\n",
       "      <td>-0.030436</td>\n",
       "      <td>-0.030643</td>\n",
       "      <td>-0.030917</td>\n",
       "      <td>-0.031127</td>\n",
       "      <td>-0.031338</td>\n",
       "      <td>-0.031409</td>\n",
       "      <td>-0.031364</td>\n",
       "      <td>-0.031465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1870 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  year Origin    type      3996      3994      3992      3990  \\\n",
       "0  2GOS-18_1955  1955    POL  living  0.016119  0.015972  0.015830  0.015728   \n",
       "1  2GOS-18_1969  1969    POL  living  0.016368  0.016543  0.016663  0.016569   \n",
       "2  2GOS-18_1974  1974    POL  living  0.021364  0.021662  0.021862  0.021573   \n",
       "3  2GOS-18_1976  1976    POL  living  0.019351  0.019246  0.019181  0.018998   \n",
       "4  2GOS-18_1996  1996    POL  living  0.018548  0.018604  0.018670  0.018616   \n",
       "\n",
       "       3988      3987  ...       417       415       413       411       409  \\\n",
       "0  0.015734  0.015787  ... -0.027973 -0.028180 -0.028389 -0.028595 -0.029011   \n",
       "1  0.016333  0.016217  ... -0.029520 -0.029747 -0.029978 -0.030204 -0.030087   \n",
       "2  0.020925  0.020585  ... -0.031046 -0.031270 -0.031483 -0.031701 -0.032089   \n",
       "3  0.018926  0.019205  ... -0.029852 -0.030092 -0.030361 -0.030647 -0.031115   \n",
       "4  0.018375  0.018266  ... -0.029963 -0.030206 -0.030436 -0.030643 -0.030917   \n",
       "\n",
       "        407       405       403       401       399  \n",
       "0 -0.029123 -0.029323 -0.029610 -0.029759 -0.029746  \n",
       "1 -0.030284 -0.030746 -0.031163 -0.031519 -0.031815  \n",
       "2 -0.032390 -0.032609 -0.032653 -0.032627 -0.032784  \n",
       "3 -0.031281 -0.031376 -0.031721 -0.032172 -0.032433  \n",
       "4 -0.031127 -0.031338 -0.031409 -0.031364 -0.031465  \n",
       "\n",
       "[5 rows x 1870 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_full = pd.read_csv(basepath+\"data/PS20191107_gegl.csv\", \n",
    "                            sep=\";\", decimal=\",\", encoding=\"utf-8\")\n",
    "data_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>3996</th>\n",
       "      <th>3994</th>\n",
       "      <th>3992</th>\n",
       "      <th>3990</th>\n",
       "      <th>3988</th>\n",
       "      <th>3987</th>\n",
       "      <th>3985</th>\n",
       "      <th>3983</th>\n",
       "      <th>3981</th>\n",
       "      <th>...</th>\n",
       "      <th>417</th>\n",
       "      <th>415</th>\n",
       "      <th>413</th>\n",
       "      <th>411</th>\n",
       "      <th>409</th>\n",
       "      <th>407</th>\n",
       "      <th>405</th>\n",
       "      <th>403</th>\n",
       "      <th>401</th>\n",
       "      <th>399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2244.000000</td>\n",
       "      <td>2244.000000</td>\n",
       "      <td>2244.000000</td>\n",
       "      <td>2244.000000</td>\n",
       "      <td>2244.000000</td>\n",
       "      <td>2244.000000</td>\n",
       "      <td>2244.000000</td>\n",
       "      <td>2244.000000</td>\n",
       "      <td>2244.000000</td>\n",
       "      <td>2244.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2244.000000</td>\n",
       "      <td>2244.000000</td>\n",
       "      <td>2244.000000</td>\n",
       "      <td>2244.000000</td>\n",
       "      <td>2244.000000</td>\n",
       "      <td>2244.000000</td>\n",
       "      <td>2244.000000</td>\n",
       "      <td>2244.000000</td>\n",
       "      <td>2244.000000</td>\n",
       "      <td>2244.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-152.291889</td>\n",
       "      <td>0.011321</td>\n",
       "      <td>0.011238</td>\n",
       "      <td>0.011167</td>\n",
       "      <td>0.011087</td>\n",
       "      <td>0.011004</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>0.010963</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>0.010838</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024586</td>\n",
       "      <td>-0.024782</td>\n",
       "      <td>-0.024978</td>\n",
       "      <td>-0.025175</td>\n",
       "      <td>-0.025414</td>\n",
       "      <td>-0.025638</td>\n",
       "      <td>-0.025847</td>\n",
       "      <td>-0.026018</td>\n",
       "      <td>-0.026165</td>\n",
       "      <td>-0.026328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3659.189806</td>\n",
       "      <td>0.005232</td>\n",
       "      <td>0.005231</td>\n",
       "      <td>0.005229</td>\n",
       "      <td>0.005212</td>\n",
       "      <td>0.005180</td>\n",
       "      <td>0.005176</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.005203</td>\n",
       "      <td>0.005198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003439</td>\n",
       "      <td>0.003428</td>\n",
       "      <td>0.003417</td>\n",
       "      <td>0.003405</td>\n",
       "      <td>0.003410</td>\n",
       "      <td>0.003386</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>0.003346</td>\n",
       "      <td>0.003334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-13555.000000</td>\n",
       "      <td>-0.002773</td>\n",
       "      <td>-0.002953</td>\n",
       "      <td>-0.002774</td>\n",
       "      <td>-0.002312</td>\n",
       "      <td>-0.002147</td>\n",
       "      <td>-0.002444</td>\n",
       "      <td>-0.003096</td>\n",
       "      <td>-0.003154</td>\n",
       "      <td>-0.003191</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035057</td>\n",
       "      <td>-0.035212</td>\n",
       "      <td>-0.035350</td>\n",
       "      <td>-0.035504</td>\n",
       "      <td>-0.036023</td>\n",
       "      <td>-0.036370</td>\n",
       "      <td>-0.036337</td>\n",
       "      <td>-0.036325</td>\n",
       "      <td>-0.036375</td>\n",
       "      <td>-0.036506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-370.250000</td>\n",
       "      <td>0.007695</td>\n",
       "      <td>0.007627</td>\n",
       "      <td>0.007587</td>\n",
       "      <td>0.007504</td>\n",
       "      <td>0.007385</td>\n",
       "      <td>0.007355</td>\n",
       "      <td>0.007297</td>\n",
       "      <td>0.007233</td>\n",
       "      <td>0.007174</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027123</td>\n",
       "      <td>-0.027286</td>\n",
       "      <td>-0.027461</td>\n",
       "      <td>-0.027654</td>\n",
       "      <td>-0.027906</td>\n",
       "      <td>-0.028134</td>\n",
       "      <td>-0.028300</td>\n",
       "      <td>-0.028394</td>\n",
       "      <td>-0.028544</td>\n",
       "      <td>-0.028711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1472.500000</td>\n",
       "      <td>0.012248</td>\n",
       "      <td>0.012160</td>\n",
       "      <td>0.012073</td>\n",
       "      <td>0.011959</td>\n",
       "      <td>0.011875</td>\n",
       "      <td>0.011864</td>\n",
       "      <td>0.011888</td>\n",
       "      <td>0.011831</td>\n",
       "      <td>0.011757</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024376</td>\n",
       "      <td>-0.024564</td>\n",
       "      <td>-0.024764</td>\n",
       "      <td>-0.024939</td>\n",
       "      <td>-0.025142</td>\n",
       "      <td>-0.025372</td>\n",
       "      <td>-0.025599</td>\n",
       "      <td>-0.025777</td>\n",
       "      <td>-0.025945</td>\n",
       "      <td>-0.026034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1806.000000</td>\n",
       "      <td>0.015064</td>\n",
       "      <td>0.014983</td>\n",
       "      <td>0.014875</td>\n",
       "      <td>0.014752</td>\n",
       "      <td>0.014673</td>\n",
       "      <td>0.014688</td>\n",
       "      <td>0.014675</td>\n",
       "      <td>0.014619</td>\n",
       "      <td>0.014553</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021932</td>\n",
       "      <td>-0.022128</td>\n",
       "      <td>-0.022342</td>\n",
       "      <td>-0.022558</td>\n",
       "      <td>-0.022820</td>\n",
       "      <td>-0.023040</td>\n",
       "      <td>-0.023253</td>\n",
       "      <td>-0.023459</td>\n",
       "      <td>-0.023626</td>\n",
       "      <td>-0.023843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2009.000000</td>\n",
       "      <td>0.028401</td>\n",
       "      <td>0.027898</td>\n",
       "      <td>0.027302</td>\n",
       "      <td>0.027014</td>\n",
       "      <td>0.026885</td>\n",
       "      <td>0.026733</td>\n",
       "      <td>0.027129</td>\n",
       "      <td>0.026971</td>\n",
       "      <td>0.026841</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013279</td>\n",
       "      <td>-0.013542</td>\n",
       "      <td>-0.013811</td>\n",
       "      <td>-0.014076</td>\n",
       "      <td>-0.014361</td>\n",
       "      <td>-0.014733</td>\n",
       "      <td>-0.015133</td>\n",
       "      <td>-0.015328</td>\n",
       "      <td>-0.015409</td>\n",
       "      <td>-0.015598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1867 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               year         3996         3994         3992         3990  \\\n",
       "count   2244.000000  2244.000000  2244.000000  2244.000000  2244.000000   \n",
       "mean    -152.291889     0.011321     0.011238     0.011167     0.011087   \n",
       "std     3659.189806     0.005232     0.005231     0.005229     0.005212   \n",
       "min   -13555.000000    -0.002773    -0.002953    -0.002774    -0.002312   \n",
       "25%     -370.250000     0.007695     0.007627     0.007587     0.007504   \n",
       "50%     1472.500000     0.012248     0.012160     0.012073     0.011959   \n",
       "75%     1806.000000     0.015064     0.014983     0.014875     0.014752   \n",
       "max     2009.000000     0.028401     0.027898     0.027302     0.027014   \n",
       "\n",
       "              3988         3987         3985         3983         3981  ...  \\\n",
       "count  2244.000000  2244.000000  2244.000000  2244.000000  2244.000000  ...   \n",
       "mean      0.011004     0.010989     0.010963     0.010900     0.010838  ...   \n",
       "std       0.005180     0.005176     0.005207     0.005203     0.005198  ...   \n",
       "min      -0.002147    -0.002444    -0.003096    -0.003154    -0.003191  ...   \n",
       "25%       0.007385     0.007355     0.007297     0.007233     0.007174  ...   \n",
       "50%       0.011875     0.011864     0.011888     0.011831     0.011757  ...   \n",
       "75%       0.014673     0.014688     0.014675     0.014619     0.014553  ...   \n",
       "max       0.026885     0.026733     0.027129     0.026971     0.026841  ...   \n",
       "\n",
       "               417          415          413          411          409  \\\n",
       "count  2244.000000  2244.000000  2244.000000  2244.000000  2244.000000   \n",
       "mean     -0.024586    -0.024782    -0.024978    -0.025175    -0.025414   \n",
       "std       0.003439     0.003428     0.003417     0.003405     0.003410   \n",
       "min      -0.035057    -0.035212    -0.035350    -0.035504    -0.036023   \n",
       "25%      -0.027123    -0.027286    -0.027461    -0.027654    -0.027906   \n",
       "50%      -0.024376    -0.024564    -0.024764    -0.024939    -0.025142   \n",
       "75%      -0.021932    -0.022128    -0.022342    -0.022558    -0.022820   \n",
       "max      -0.013279    -0.013542    -0.013811    -0.014076    -0.014361   \n",
       "\n",
       "               407          405          403          401          399  \n",
       "count  2244.000000  2244.000000  2244.000000  2244.000000  2244.000000  \n",
       "mean     -0.025638    -0.025847    -0.026018    -0.026165    -0.026328  \n",
       "std       0.003386     0.003367     0.003356     0.003346     0.003334  \n",
       "min      -0.036370    -0.036337    -0.036325    -0.036375    -0.036506  \n",
       "25%      -0.028134    -0.028300    -0.028394    -0.028544    -0.028711  \n",
       "50%      -0.025372    -0.025599    -0.025777    -0.025945    -0.026034  \n",
       "75%      -0.023040    -0.023253    -0.023459    -0.023626    -0.023843  \n",
       "max      -0.014733    -0.015133    -0.015328    -0.015409    -0.015598  \n",
       "\n",
       "[8 rows x 1867 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrive basic characteristics for each variable\n",
    "data_full.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>constr</th>\n",
       "      <td>1936</td>\n",
       "      <td>1628.966667</td>\n",
       "      <td>1239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dry</th>\n",
       "      <td>1765</td>\n",
       "      <td>948.591716</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>living</th>\n",
       "      <td>2009</td>\n",
       "      <td>1886.843700</td>\n",
       "      <td>1524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>1912</td>\n",
       "      <td>-2682.173774</td>\n",
       "      <td>-13555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        year                    \n",
       "         max         mean    min\n",
       "type                            \n",
       "constr  1936  1628.966667   1239\n",
       "dry     1765   948.591716    327\n",
       "living  2009  1886.843700   1524\n",
       "water   1912 -2682.173774 -13555"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full.groupby('type')[['year']].agg(['max', 'mean', 'min'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset dps1200.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>year</th>\n",
       "      <th>tree</th>\n",
       "      <th>Origin</th>\n",
       "      <th>type</th>\n",
       "      <th>X2970</th>\n",
       "      <th>X2968</th>\n",
       "      <th>X2966</th>\n",
       "      <th>X2964</th>\n",
       "      <th>X2962</th>\n",
       "      <th>...</th>\n",
       "      <th>X818</th>\n",
       "      <th>X816</th>\n",
       "      <th>X814</th>\n",
       "      <th>X812</th>\n",
       "      <th>X810</th>\n",
       "      <th>X808</th>\n",
       "      <th>X806</th>\n",
       "      <th>X804</th>\n",
       "      <th>X802</th>\n",
       "      <th>X800</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2GOS-18_1955</td>\n",
       "      <td>1955</td>\n",
       "      <td>2GOS-18</td>\n",
       "      <td>POL</td>\n",
       "      <td>living</td>\n",
       "      <td>0.019849</td>\n",
       "      <td>0.020121</td>\n",
       "      <td>0.020414</td>\n",
       "      <td>0.020724</td>\n",
       "      <td>0.021030</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023469</td>\n",
       "      <td>-0.023367</td>\n",
       "      <td>-0.023283</td>\n",
       "      <td>-0.023220</td>\n",
       "      <td>-0.023183</td>\n",
       "      <td>-0.023174</td>\n",
       "      <td>-0.023190</td>\n",
       "      <td>-0.023228</td>\n",
       "      <td>-0.023293</td>\n",
       "      <td>-0.023388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2GOS-18_1969</td>\n",
       "      <td>1969</td>\n",
       "      <td>2GOS-18</td>\n",
       "      <td>POL</td>\n",
       "      <td>living</td>\n",
       "      <td>0.023933</td>\n",
       "      <td>0.024378</td>\n",
       "      <td>0.024827</td>\n",
       "      <td>0.025273</td>\n",
       "      <td>0.025712</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024117</td>\n",
       "      <td>-0.024076</td>\n",
       "      <td>-0.024043</td>\n",
       "      <td>-0.024021</td>\n",
       "      <td>-0.024015</td>\n",
       "      <td>-0.024033</td>\n",
       "      <td>-0.024077</td>\n",
       "      <td>-0.024147</td>\n",
       "      <td>-0.024238</td>\n",
       "      <td>-0.024346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2GOS-18_1974</td>\n",
       "      <td>1974</td>\n",
       "      <td>2GOS-18</td>\n",
       "      <td>POL</td>\n",
       "      <td>living</td>\n",
       "      <td>0.021605</td>\n",
       "      <td>0.021971</td>\n",
       "      <td>0.022342</td>\n",
       "      <td>0.022719</td>\n",
       "      <td>0.023099</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026266</td>\n",
       "      <td>-0.026214</td>\n",
       "      <td>-0.026172</td>\n",
       "      <td>-0.026149</td>\n",
       "      <td>-0.026146</td>\n",
       "      <td>-0.026165</td>\n",
       "      <td>-0.026208</td>\n",
       "      <td>-0.026273</td>\n",
       "      <td>-0.026363</td>\n",
       "      <td>-0.026479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2GOS-18_1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>2GOS-18</td>\n",
       "      <td>POL</td>\n",
       "      <td>living</td>\n",
       "      <td>0.021999</td>\n",
       "      <td>0.022315</td>\n",
       "      <td>0.022651</td>\n",
       "      <td>0.022999</td>\n",
       "      <td>0.023345</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025113</td>\n",
       "      <td>-0.025030</td>\n",
       "      <td>-0.024959</td>\n",
       "      <td>-0.024909</td>\n",
       "      <td>-0.024885</td>\n",
       "      <td>-0.024888</td>\n",
       "      <td>-0.024918</td>\n",
       "      <td>-0.024971</td>\n",
       "      <td>-0.025049</td>\n",
       "      <td>-0.025153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2GOS-18_1996</td>\n",
       "      <td>1996</td>\n",
       "      <td>2GOS-18</td>\n",
       "      <td>POL</td>\n",
       "      <td>living</td>\n",
       "      <td>0.021031</td>\n",
       "      <td>0.021338</td>\n",
       "      <td>0.021626</td>\n",
       "      <td>0.021923</td>\n",
       "      <td>0.022248</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025256</td>\n",
       "      <td>-0.025158</td>\n",
       "      <td>-0.025083</td>\n",
       "      <td>-0.025035</td>\n",
       "      <td>-0.025013</td>\n",
       "      <td>-0.025015</td>\n",
       "      <td>-0.025040</td>\n",
       "      <td>-0.025094</td>\n",
       "      <td>-0.025177</td>\n",
       "      <td>-0.025282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 415 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  year     tree Origin    type     X2970     X2968     X2966  \\\n",
       "0  2GOS-18_1955  1955  2GOS-18    POL  living  0.019849  0.020121  0.020414   \n",
       "1  2GOS-18_1969  1969  2GOS-18    POL  living  0.023933  0.024378  0.024827   \n",
       "2  2GOS-18_1974  1974  2GOS-18    POL  living  0.021605  0.021971  0.022342   \n",
       "3  2GOS-18_1976  1976  2GOS-18    POL  living  0.021999  0.022315  0.022651   \n",
       "4  2GOS-18_1996  1996  2GOS-18    POL  living  0.021031  0.021338  0.021626   \n",
       "\n",
       "      X2964     X2962  ...      X818      X816      X814      X812      X810  \\\n",
       "0  0.020724  0.021030  ... -0.023469 -0.023367 -0.023283 -0.023220 -0.023183   \n",
       "1  0.025273  0.025712  ... -0.024117 -0.024076 -0.024043 -0.024021 -0.024015   \n",
       "2  0.022719  0.023099  ... -0.026266 -0.026214 -0.026172 -0.026149 -0.026146   \n",
       "3  0.022999  0.023345  ... -0.025113 -0.025030 -0.024959 -0.024909 -0.024885   \n",
       "4  0.021923  0.022248  ... -0.025256 -0.025158 -0.025083 -0.025035 -0.025013   \n",
       "\n",
       "       X808      X806      X804      X802      X800  \n",
       "0 -0.023174 -0.023190 -0.023228 -0.023293 -0.023388  \n",
       "1 -0.024033 -0.024077 -0.024147 -0.024238 -0.024346  \n",
       "2 -0.026165 -0.026208 -0.026273 -0.026363 -0.026479  \n",
       "3 -0.024888 -0.024918 -0.024971 -0.025049 -0.025153  \n",
       "4 -0.025015 -0.025040 -0.025094 -0.025177 -0.025282  \n",
       "\n",
       "[5 rows x 415 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_small = pd.read_csv(basepath+\"data/dps1200.csv\", \n",
    "                            sep=\",\", decimal=\".\", encoding=\"utf-8\")\n",
    "data_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>year</th>\n",
       "      <th>tree</th>\n",
       "      <th>Origin</th>\n",
       "      <th>type</th>\n",
       "      <th>2970</th>\n",
       "      <th>2968</th>\n",
       "      <th>2966</th>\n",
       "      <th>2964</th>\n",
       "      <th>2962</th>\n",
       "      <th>...</th>\n",
       "      <th>818</th>\n",
       "      <th>816</th>\n",
       "      <th>814</th>\n",
       "      <th>812</th>\n",
       "      <th>810</th>\n",
       "      <th>808</th>\n",
       "      <th>806</th>\n",
       "      <th>804</th>\n",
       "      <th>802</th>\n",
       "      <th>800</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2GOS-18_1955</td>\n",
       "      <td>1955</td>\n",
       "      <td>2GOS-18</td>\n",
       "      <td>POL</td>\n",
       "      <td>living</td>\n",
       "      <td>0.019849</td>\n",
       "      <td>0.020121</td>\n",
       "      <td>0.020414</td>\n",
       "      <td>0.020724</td>\n",
       "      <td>0.021030</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023469</td>\n",
       "      <td>-0.023367</td>\n",
       "      <td>-0.023283</td>\n",
       "      <td>-0.023220</td>\n",
       "      <td>-0.023183</td>\n",
       "      <td>-0.023174</td>\n",
       "      <td>-0.023190</td>\n",
       "      <td>-0.023228</td>\n",
       "      <td>-0.023293</td>\n",
       "      <td>-0.023388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2GOS-18_1969</td>\n",
       "      <td>1969</td>\n",
       "      <td>2GOS-18</td>\n",
       "      <td>POL</td>\n",
       "      <td>living</td>\n",
       "      <td>0.023933</td>\n",
       "      <td>0.024378</td>\n",
       "      <td>0.024827</td>\n",
       "      <td>0.025273</td>\n",
       "      <td>0.025712</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024117</td>\n",
       "      <td>-0.024076</td>\n",
       "      <td>-0.024043</td>\n",
       "      <td>-0.024021</td>\n",
       "      <td>-0.024015</td>\n",
       "      <td>-0.024033</td>\n",
       "      <td>-0.024077</td>\n",
       "      <td>-0.024147</td>\n",
       "      <td>-0.024238</td>\n",
       "      <td>-0.024346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2GOS-18_1974</td>\n",
       "      <td>1974</td>\n",
       "      <td>2GOS-18</td>\n",
       "      <td>POL</td>\n",
       "      <td>living</td>\n",
       "      <td>0.021605</td>\n",
       "      <td>0.021971</td>\n",
       "      <td>0.022342</td>\n",
       "      <td>0.022719</td>\n",
       "      <td>0.023099</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026266</td>\n",
       "      <td>-0.026214</td>\n",
       "      <td>-0.026172</td>\n",
       "      <td>-0.026149</td>\n",
       "      <td>-0.026146</td>\n",
       "      <td>-0.026165</td>\n",
       "      <td>-0.026208</td>\n",
       "      <td>-0.026273</td>\n",
       "      <td>-0.026363</td>\n",
       "      <td>-0.026479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2GOS-18_1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>2GOS-18</td>\n",
       "      <td>POL</td>\n",
       "      <td>living</td>\n",
       "      <td>0.021999</td>\n",
       "      <td>0.022315</td>\n",
       "      <td>0.022651</td>\n",
       "      <td>0.022999</td>\n",
       "      <td>0.023345</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025113</td>\n",
       "      <td>-0.025030</td>\n",
       "      <td>-0.024959</td>\n",
       "      <td>-0.024909</td>\n",
       "      <td>-0.024885</td>\n",
       "      <td>-0.024888</td>\n",
       "      <td>-0.024918</td>\n",
       "      <td>-0.024971</td>\n",
       "      <td>-0.025049</td>\n",
       "      <td>-0.025153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2GOS-18_1996</td>\n",
       "      <td>1996</td>\n",
       "      <td>2GOS-18</td>\n",
       "      <td>POL</td>\n",
       "      <td>living</td>\n",
       "      <td>0.021031</td>\n",
       "      <td>0.021338</td>\n",
       "      <td>0.021626</td>\n",
       "      <td>0.021923</td>\n",
       "      <td>0.022248</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025256</td>\n",
       "      <td>-0.025158</td>\n",
       "      <td>-0.025083</td>\n",
       "      <td>-0.025035</td>\n",
       "      <td>-0.025013</td>\n",
       "      <td>-0.025015</td>\n",
       "      <td>-0.025040</td>\n",
       "      <td>-0.025094</td>\n",
       "      <td>-0.025177</td>\n",
       "      <td>-0.025282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 415 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  year     tree Origin    type      2970      2968      2966  \\\n",
       "0  2GOS-18_1955  1955  2GOS-18    POL  living  0.019849  0.020121  0.020414   \n",
       "1  2GOS-18_1969  1969  2GOS-18    POL  living  0.023933  0.024378  0.024827   \n",
       "2  2GOS-18_1974  1974  2GOS-18    POL  living  0.021605  0.021971  0.022342   \n",
       "3  2GOS-18_1976  1976  2GOS-18    POL  living  0.021999  0.022315  0.022651   \n",
       "4  2GOS-18_1996  1996  2GOS-18    POL  living  0.021031  0.021338  0.021626   \n",
       "\n",
       "       2964      2962  ...       818       816       814       812       810  \\\n",
       "0  0.020724  0.021030  ... -0.023469 -0.023367 -0.023283 -0.023220 -0.023183   \n",
       "1  0.025273  0.025712  ... -0.024117 -0.024076 -0.024043 -0.024021 -0.024015   \n",
       "2  0.022719  0.023099  ... -0.026266 -0.026214 -0.026172 -0.026149 -0.026146   \n",
       "3  0.022999  0.023345  ... -0.025113 -0.025030 -0.024959 -0.024909 -0.024885   \n",
       "4  0.021923  0.022248  ... -0.025256 -0.025158 -0.025083 -0.025035 -0.025013   \n",
       "\n",
       "        808       806       804       802       800  \n",
       "0 -0.023174 -0.023190 -0.023228 -0.023293 -0.023388  \n",
       "1 -0.024033 -0.024077 -0.024147 -0.024238 -0.024346  \n",
       "2 -0.026165 -0.026208 -0.026273 -0.026363 -0.026479  \n",
       "3 -0.024888 -0.024918 -0.024971 -0.025049 -0.025153  \n",
       "4 -0.025015 -0.025040 -0.025094 -0.025177 -0.025282  \n",
       "\n",
       "[5 rows x 415 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correct the column headers\n",
    "\n",
    "# data_1200.rename(lambda x: x[1:], axis='columns')\n",
    "data_small = data_small.rename(columns=lambda x: x.replace('X', ''))\n",
    "data_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>2970</th>\n",
       "      <th>2968</th>\n",
       "      <th>2966</th>\n",
       "      <th>2964</th>\n",
       "      <th>2962</th>\n",
       "      <th>2960</th>\n",
       "      <th>2959</th>\n",
       "      <th>2957</th>\n",
       "      <th>2955</th>\n",
       "      <th>...</th>\n",
       "      <th>818</th>\n",
       "      <th>816</th>\n",
       "      <th>814</th>\n",
       "      <th>812</th>\n",
       "      <th>810</th>\n",
       "      <th>808</th>\n",
       "      <th>806</th>\n",
       "      <th>804</th>\n",
       "      <th>802</th>\n",
       "      <th>800</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1290.000000</td>\n",
       "      <td>1290.000000</td>\n",
       "      <td>1290.000000</td>\n",
       "      <td>1290.000000</td>\n",
       "      <td>1290.000000</td>\n",
       "      <td>1290.000000</td>\n",
       "      <td>1290.000000</td>\n",
       "      <td>1290.000000</td>\n",
       "      <td>1290.000000</td>\n",
       "      <td>1290.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1290.000000</td>\n",
       "      <td>1290.000000</td>\n",
       "      <td>1290.000000</td>\n",
       "      <td>1290.000000</td>\n",
       "      <td>1290.000000</td>\n",
       "      <td>1290.000000</td>\n",
       "      <td>1290.000000</td>\n",
       "      <td>1290.000000</td>\n",
       "      <td>1290.000000</td>\n",
       "      <td>1290.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1740.420930</td>\n",
       "      <td>0.018827</td>\n",
       "      <td>0.019122</td>\n",
       "      <td>0.019427</td>\n",
       "      <td>0.019740</td>\n",
       "      <td>0.020061</td>\n",
       "      <td>0.020389</td>\n",
       "      <td>0.020728</td>\n",
       "      <td>0.021078</td>\n",
       "      <td>0.021439</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020705</td>\n",
       "      <td>-0.020572</td>\n",
       "      <td>-0.020456</td>\n",
       "      <td>-0.020361</td>\n",
       "      <td>-0.020292</td>\n",
       "      <td>-0.020254</td>\n",
       "      <td>-0.020248</td>\n",
       "      <td>-0.020276</td>\n",
       "      <td>-0.020335</td>\n",
       "      <td>-0.020420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>196.420289</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.002163</td>\n",
       "      <td>0.002223</td>\n",
       "      <td>0.002279</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>0.002385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002526</td>\n",
       "      <td>0.002560</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>0.002622</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.002673</td>\n",
       "      <td>0.002693</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>0.002723</td>\n",
       "      <td>0.002735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1194.000000</td>\n",
       "      <td>0.011339</td>\n",
       "      <td>0.011597</td>\n",
       "      <td>0.011871</td>\n",
       "      <td>0.012159</td>\n",
       "      <td>0.012466</td>\n",
       "      <td>0.012791</td>\n",
       "      <td>0.013134</td>\n",
       "      <td>0.013493</td>\n",
       "      <td>0.013861</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026419</td>\n",
       "      <td>-0.026362</td>\n",
       "      <td>-0.026319</td>\n",
       "      <td>-0.026296</td>\n",
       "      <td>-0.026293</td>\n",
       "      <td>-0.026308</td>\n",
       "      <td>-0.026335</td>\n",
       "      <td>-0.026373</td>\n",
       "      <td>-0.026451</td>\n",
       "      <td>-0.026601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1616.000000</td>\n",
       "      <td>0.017552</td>\n",
       "      <td>0.017789</td>\n",
       "      <td>0.018044</td>\n",
       "      <td>0.018325</td>\n",
       "      <td>0.018587</td>\n",
       "      <td>0.018869</td>\n",
       "      <td>0.019175</td>\n",
       "      <td>0.019468</td>\n",
       "      <td>0.019784</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022815</td>\n",
       "      <td>-0.022723</td>\n",
       "      <td>-0.022603</td>\n",
       "      <td>-0.022533</td>\n",
       "      <td>-0.022505</td>\n",
       "      <td>-0.022469</td>\n",
       "      <td>-0.022500</td>\n",
       "      <td>-0.022531</td>\n",
       "      <td>-0.022616</td>\n",
       "      <td>-0.022704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1769.000000</td>\n",
       "      <td>0.018673</td>\n",
       "      <td>0.018942</td>\n",
       "      <td>0.019230</td>\n",
       "      <td>0.019521</td>\n",
       "      <td>0.019805</td>\n",
       "      <td>0.020112</td>\n",
       "      <td>0.020430</td>\n",
       "      <td>0.020781</td>\n",
       "      <td>0.021118</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020678</td>\n",
       "      <td>-0.020497</td>\n",
       "      <td>-0.020383</td>\n",
       "      <td>-0.020287</td>\n",
       "      <td>-0.020214</td>\n",
       "      <td>-0.020141</td>\n",
       "      <td>-0.020116</td>\n",
       "      <td>-0.020118</td>\n",
       "      <td>-0.020152</td>\n",
       "      <td>-0.020231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1913.000000</td>\n",
       "      <td>0.019991</td>\n",
       "      <td>0.020269</td>\n",
       "      <td>0.020567</td>\n",
       "      <td>0.020911</td>\n",
       "      <td>0.021258</td>\n",
       "      <td>0.021605</td>\n",
       "      <td>0.021966</td>\n",
       "      <td>0.022307</td>\n",
       "      <td>0.022655</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018458</td>\n",
       "      <td>-0.018294</td>\n",
       "      <td>-0.018154</td>\n",
       "      <td>-0.018033</td>\n",
       "      <td>-0.017950</td>\n",
       "      <td>-0.017888</td>\n",
       "      <td>-0.017871</td>\n",
       "      <td>-0.017885</td>\n",
       "      <td>-0.017919</td>\n",
       "      <td>-0.017988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2009.000000</td>\n",
       "      <td>0.027378</td>\n",
       "      <td>0.028247</td>\n",
       "      <td>0.029124</td>\n",
       "      <td>0.029990</td>\n",
       "      <td>0.030832</td>\n",
       "      <td>0.031645</td>\n",
       "      <td>0.032436</td>\n",
       "      <td>0.033220</td>\n",
       "      <td>0.034017</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013677</td>\n",
       "      <td>-0.013408</td>\n",
       "      <td>-0.013178</td>\n",
       "      <td>-0.012991</td>\n",
       "      <td>-0.012843</td>\n",
       "      <td>-0.012738</td>\n",
       "      <td>-0.012686</td>\n",
       "      <td>-0.012691</td>\n",
       "      <td>-0.012745</td>\n",
       "      <td>-0.012844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              year         2970         2968         2966         2964  \\\n",
       "count  1290.000000  1290.000000  1290.000000  1290.000000  1290.000000   \n",
       "mean   1740.420930     0.018827     0.019122     0.019427     0.019740   \n",
       "std     196.420289     0.001922     0.001978     0.002038     0.002100   \n",
       "min    1194.000000     0.011339     0.011597     0.011871     0.012159   \n",
       "25%    1616.000000     0.017552     0.017789     0.018044     0.018325   \n",
       "50%    1769.000000     0.018673     0.018942     0.019230     0.019521   \n",
       "75%    1913.000000     0.019991     0.020269     0.020567     0.020911   \n",
       "max    2009.000000     0.027378     0.028247     0.029124     0.029990   \n",
       "\n",
       "              2962         2960         2959         2957         2955  ...  \\\n",
       "count  1290.000000  1290.000000  1290.000000  1290.000000  1290.000000  ...   \n",
       "mean      0.020061     0.020389     0.020728     0.021078     0.021439  ...   \n",
       "std       0.002163     0.002223     0.002279     0.002333     0.002385  ...   \n",
       "min       0.012466     0.012791     0.013134     0.013493     0.013861  ...   \n",
       "25%       0.018587     0.018869     0.019175     0.019468     0.019784  ...   \n",
       "50%       0.019805     0.020112     0.020430     0.020781     0.021118  ...   \n",
       "75%       0.021258     0.021605     0.021966     0.022307     0.022655  ...   \n",
       "max       0.030832     0.031645     0.032436     0.033220     0.034017  ...   \n",
       "\n",
       "               818          816          814          812          810  \\\n",
       "count  1290.000000  1290.000000  1290.000000  1290.000000  1290.000000   \n",
       "mean     -0.020705    -0.020572    -0.020456    -0.020361    -0.020292   \n",
       "std       0.002526     0.002560     0.002593     0.002622     0.002649   \n",
       "min      -0.026419    -0.026362    -0.026319    -0.026296    -0.026293   \n",
       "25%      -0.022815    -0.022723    -0.022603    -0.022533    -0.022505   \n",
       "50%      -0.020678    -0.020497    -0.020383    -0.020287    -0.020214   \n",
       "75%      -0.018458    -0.018294    -0.018154    -0.018033    -0.017950   \n",
       "max      -0.013677    -0.013408    -0.013178    -0.012991    -0.012843   \n",
       "\n",
       "               808          806          804          802          800  \n",
       "count  1290.000000  1290.000000  1290.000000  1290.000000  1290.000000  \n",
       "mean     -0.020254    -0.020248    -0.020276    -0.020335    -0.020420  \n",
       "std       0.002673     0.002693     0.002710     0.002723     0.002735  \n",
       "min      -0.026308    -0.026335    -0.026373    -0.026451    -0.026601  \n",
       "25%      -0.022469    -0.022500    -0.022531    -0.022616    -0.022704  \n",
       "50%      -0.020141    -0.020116    -0.020118    -0.020152    -0.020231  \n",
       "75%      -0.017888    -0.017871    -0.017885    -0.017919    -0.017988  \n",
       "max      -0.012738    -0.012686    -0.012691    -0.012745    -0.012844  \n",
       "\n",
       "[8 rows x 411 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_small.describe()\n",
    "# describe() gives some basic statistics for numeric columns,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tree</th>\n",
       "      <th>Origin</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1290</td>\n",
       "      <td>1290</td>\n",
       "      <td>1290</td>\n",
       "      <td>1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1290</td>\n",
       "      <td>139</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>SZLPS15a_1982</td>\n",
       "      <td>Dev2b</td>\n",
       "      <td>AUT</td>\n",
       "      <td>living</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>631</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Unnamed: 0   tree Origin    type\n",
       "count            1290   1290   1290    1290\n",
       "unique           1290    139      4       4\n",
       "top     SZLPS15a_1982  Dev2b    AUT  living\n",
       "freq                1     29    631     627"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_small.describe(include=\"object\")\n",
    "# describe() gives some basic statistics for numeric columns, \n",
    "# categorial columns are included with the option include=\"object\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extensive mode for Cross Validation\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters for the CV\n",
    "\n",
    "# Switch for the dataset\n",
    "    # Select from (data_1200, data_full) or other if implemented\n",
    "data = data_small\n",
    "\n",
    "# Switch for testing mode (use only 10% of the data, among others)\n",
    "testing = False\n",
    "\n",
    "# Define a random state for randomized processes\n",
    "random_state = np.random.RandomState(202375)\n",
    "\n",
    "# Define a metric for model evaluation\n",
    "cv_scorer = 'neg_mean_squared_error'\n",
    "\n",
    "######################################################\n",
    "if testing == True:\n",
    "    nfolds = 2\n",
    "    NoTrials = 2\n",
    "    n_jobs = 20\n",
    "    save_model = False\n",
    "    print(\"Testing mode for Cross Validation\")\n",
    "    print(\"Splitting the data for faster modelling\")\n",
    "    data = data.sample(frac=0.1)\n",
    "else:\n",
    "    nfolds = 10\n",
    "    NoTrials = 15\n",
    "    n_jobs = 40\n",
    "    save_model = True\n",
    "    print(\"Extensive mode for Cross Validation\")\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2970</th>\n",
       "      <th>2968</th>\n",
       "      <th>2966</th>\n",
       "      <th>2964</th>\n",
       "      <th>2962</th>\n",
       "      <th>2960</th>\n",
       "      <th>2959</th>\n",
       "      <th>2957</th>\n",
       "      <th>2955</th>\n",
       "      <th>2953</th>\n",
       "      <th>...</th>\n",
       "      <th>818</th>\n",
       "      <th>816</th>\n",
       "      <th>814</th>\n",
       "      <th>812</th>\n",
       "      <th>810</th>\n",
       "      <th>808</th>\n",
       "      <th>806</th>\n",
       "      <th>804</th>\n",
       "      <th>802</th>\n",
       "      <th>800</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.019849</td>\n",
       "      <td>0.020121</td>\n",
       "      <td>0.020414</td>\n",
       "      <td>0.020724</td>\n",
       "      <td>0.021030</td>\n",
       "      <td>0.021321</td>\n",
       "      <td>0.021615</td>\n",
       "      <td>0.021931</td>\n",
       "      <td>0.022270</td>\n",
       "      <td>0.022634</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023469</td>\n",
       "      <td>-0.023367</td>\n",
       "      <td>-0.023283</td>\n",
       "      <td>-0.023220</td>\n",
       "      <td>-0.023183</td>\n",
       "      <td>-0.023174</td>\n",
       "      <td>-0.023190</td>\n",
       "      <td>-0.023228</td>\n",
       "      <td>-0.023293</td>\n",
       "      <td>-0.023388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023933</td>\n",
       "      <td>0.024378</td>\n",
       "      <td>0.024827</td>\n",
       "      <td>0.025273</td>\n",
       "      <td>0.025712</td>\n",
       "      <td>0.026149</td>\n",
       "      <td>0.026586</td>\n",
       "      <td>0.027030</td>\n",
       "      <td>0.027490</td>\n",
       "      <td>0.027963</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024117</td>\n",
       "      <td>-0.024076</td>\n",
       "      <td>-0.024043</td>\n",
       "      <td>-0.024021</td>\n",
       "      <td>-0.024015</td>\n",
       "      <td>-0.024033</td>\n",
       "      <td>-0.024077</td>\n",
       "      <td>-0.024147</td>\n",
       "      <td>-0.024238</td>\n",
       "      <td>-0.024346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021605</td>\n",
       "      <td>0.021971</td>\n",
       "      <td>0.022342</td>\n",
       "      <td>0.022719</td>\n",
       "      <td>0.023099</td>\n",
       "      <td>0.023470</td>\n",
       "      <td>0.023832</td>\n",
       "      <td>0.024207</td>\n",
       "      <td>0.024610</td>\n",
       "      <td>0.025038</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026266</td>\n",
       "      <td>-0.026214</td>\n",
       "      <td>-0.026172</td>\n",
       "      <td>-0.026149</td>\n",
       "      <td>-0.026146</td>\n",
       "      <td>-0.026165</td>\n",
       "      <td>-0.026208</td>\n",
       "      <td>-0.026273</td>\n",
       "      <td>-0.026363</td>\n",
       "      <td>-0.026479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.021999</td>\n",
       "      <td>0.022315</td>\n",
       "      <td>0.022651</td>\n",
       "      <td>0.022999</td>\n",
       "      <td>0.023345</td>\n",
       "      <td>0.023682</td>\n",
       "      <td>0.024023</td>\n",
       "      <td>0.024386</td>\n",
       "      <td>0.024768</td>\n",
       "      <td>0.025150</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025113</td>\n",
       "      <td>-0.025030</td>\n",
       "      <td>-0.024959</td>\n",
       "      <td>-0.024909</td>\n",
       "      <td>-0.024885</td>\n",
       "      <td>-0.024888</td>\n",
       "      <td>-0.024918</td>\n",
       "      <td>-0.024971</td>\n",
       "      <td>-0.025049</td>\n",
       "      <td>-0.025153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.021031</td>\n",
       "      <td>0.021338</td>\n",
       "      <td>0.021626</td>\n",
       "      <td>0.021923</td>\n",
       "      <td>0.022248</td>\n",
       "      <td>0.022589</td>\n",
       "      <td>0.022925</td>\n",
       "      <td>0.023264</td>\n",
       "      <td>0.023624</td>\n",
       "      <td>0.024004</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025256</td>\n",
       "      <td>-0.025158</td>\n",
       "      <td>-0.025083</td>\n",
       "      <td>-0.025035</td>\n",
       "      <td>-0.025013</td>\n",
       "      <td>-0.025015</td>\n",
       "      <td>-0.025040</td>\n",
       "      <td>-0.025094</td>\n",
       "      <td>-0.025177</td>\n",
       "      <td>-0.025282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>0.018254</td>\n",
       "      <td>0.018577</td>\n",
       "      <td>0.018906</td>\n",
       "      <td>0.019248</td>\n",
       "      <td>0.019604</td>\n",
       "      <td>0.019962</td>\n",
       "      <td>0.020317</td>\n",
       "      <td>0.020670</td>\n",
       "      <td>0.021035</td>\n",
       "      <td>0.021428</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018632</td>\n",
       "      <td>-0.018450</td>\n",
       "      <td>-0.018285</td>\n",
       "      <td>-0.018149</td>\n",
       "      <td>-0.018048</td>\n",
       "      <td>-0.017984</td>\n",
       "      <td>-0.017955</td>\n",
       "      <td>-0.017961</td>\n",
       "      <td>-0.017997</td>\n",
       "      <td>-0.018058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>0.018508</td>\n",
       "      <td>0.018778</td>\n",
       "      <td>0.019051</td>\n",
       "      <td>0.019341</td>\n",
       "      <td>0.019650</td>\n",
       "      <td>0.019962</td>\n",
       "      <td>0.020274</td>\n",
       "      <td>0.020597</td>\n",
       "      <td>0.020944</td>\n",
       "      <td>0.021318</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019053</td>\n",
       "      <td>-0.018876</td>\n",
       "      <td>-0.018717</td>\n",
       "      <td>-0.018583</td>\n",
       "      <td>-0.018481</td>\n",
       "      <td>-0.018413</td>\n",
       "      <td>-0.018380</td>\n",
       "      <td>-0.018379</td>\n",
       "      <td>-0.018410</td>\n",
       "      <td>-0.018469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>0.017196</td>\n",
       "      <td>0.017486</td>\n",
       "      <td>0.017786</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.018423</td>\n",
       "      <td>0.018749</td>\n",
       "      <td>0.019080</td>\n",
       "      <td>0.019421</td>\n",
       "      <td>0.019777</td>\n",
       "      <td>0.020150</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018587</td>\n",
       "      <td>-0.018406</td>\n",
       "      <td>-0.018242</td>\n",
       "      <td>-0.018103</td>\n",
       "      <td>-0.017993</td>\n",
       "      <td>-0.017912</td>\n",
       "      <td>-0.017865</td>\n",
       "      <td>-0.017854</td>\n",
       "      <td>-0.017877</td>\n",
       "      <td>-0.017928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>0.017298</td>\n",
       "      <td>0.017541</td>\n",
       "      <td>0.017791</td>\n",
       "      <td>0.018060</td>\n",
       "      <td>0.018352</td>\n",
       "      <td>0.018656</td>\n",
       "      <td>0.018964</td>\n",
       "      <td>0.019273</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>0.019929</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018916</td>\n",
       "      <td>-0.018720</td>\n",
       "      <td>-0.018541</td>\n",
       "      <td>-0.018390</td>\n",
       "      <td>-0.018273</td>\n",
       "      <td>-0.018189</td>\n",
       "      <td>-0.018138</td>\n",
       "      <td>-0.018122</td>\n",
       "      <td>-0.018142</td>\n",
       "      <td>-0.018194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>0.017682</td>\n",
       "      <td>0.017931</td>\n",
       "      <td>0.018186</td>\n",
       "      <td>0.018456</td>\n",
       "      <td>0.018740</td>\n",
       "      <td>0.019026</td>\n",
       "      <td>0.019317</td>\n",
       "      <td>0.019621</td>\n",
       "      <td>0.019942</td>\n",
       "      <td>0.020279</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018848</td>\n",
       "      <td>-0.018661</td>\n",
       "      <td>-0.018488</td>\n",
       "      <td>-0.018340</td>\n",
       "      <td>-0.018227</td>\n",
       "      <td>-0.018148</td>\n",
       "      <td>-0.018104</td>\n",
       "      <td>-0.018094</td>\n",
       "      <td>-0.018115</td>\n",
       "      <td>-0.018165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1290 rows × 410 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          2970      2968      2966      2964      2962      2960      2959  \\\n",
       "0     0.019849  0.020121  0.020414  0.020724  0.021030  0.021321  0.021615   \n",
       "1     0.023933  0.024378  0.024827  0.025273  0.025712  0.026149  0.026586   \n",
       "2     0.021605  0.021971  0.022342  0.022719  0.023099  0.023470  0.023832   \n",
       "3     0.021999  0.022315  0.022651  0.022999  0.023345  0.023682  0.024023   \n",
       "4     0.021031  0.021338  0.021626  0.021923  0.022248  0.022589  0.022925   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1285  0.018254  0.018577  0.018906  0.019248  0.019604  0.019962  0.020317   \n",
       "1286  0.018508  0.018778  0.019051  0.019341  0.019650  0.019962  0.020274   \n",
       "1287  0.017196  0.017486  0.017786  0.018100  0.018423  0.018749  0.019080   \n",
       "1288  0.017298  0.017541  0.017791  0.018060  0.018352  0.018656  0.018964   \n",
       "1289  0.017682  0.017931  0.018186  0.018456  0.018740  0.019026  0.019317   \n",
       "\n",
       "          2957      2955      2953  ...       818       816       814  \\\n",
       "0     0.021931  0.022270  0.022634  ... -0.023469 -0.023367 -0.023283   \n",
       "1     0.027030  0.027490  0.027963  ... -0.024117 -0.024076 -0.024043   \n",
       "2     0.024207  0.024610  0.025038  ... -0.026266 -0.026214 -0.026172   \n",
       "3     0.024386  0.024768  0.025150  ... -0.025113 -0.025030 -0.024959   \n",
       "4     0.023264  0.023624  0.024004  ... -0.025256 -0.025158 -0.025083   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1285  0.020670  0.021035  0.021428  ... -0.018632 -0.018450 -0.018285   \n",
       "1286  0.020597  0.020944  0.021318  ... -0.019053 -0.018876 -0.018717   \n",
       "1287  0.019421  0.019777  0.020150  ... -0.018587 -0.018406 -0.018242   \n",
       "1288  0.019273  0.019592  0.019929  ... -0.018916 -0.018720 -0.018541   \n",
       "1289  0.019621  0.019942  0.020279  ... -0.018848 -0.018661 -0.018488   \n",
       "\n",
       "           812       810       808       806       804       802       800  \n",
       "0    -0.023220 -0.023183 -0.023174 -0.023190 -0.023228 -0.023293 -0.023388  \n",
       "1    -0.024021 -0.024015 -0.024033 -0.024077 -0.024147 -0.024238 -0.024346  \n",
       "2    -0.026149 -0.026146 -0.026165 -0.026208 -0.026273 -0.026363 -0.026479  \n",
       "3    -0.024909 -0.024885 -0.024888 -0.024918 -0.024971 -0.025049 -0.025153  \n",
       "4    -0.025035 -0.025013 -0.025015 -0.025040 -0.025094 -0.025177 -0.025282  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1285 -0.018149 -0.018048 -0.017984 -0.017955 -0.017961 -0.017997 -0.018058  \n",
       "1286 -0.018583 -0.018481 -0.018413 -0.018380 -0.018379 -0.018410 -0.018469  \n",
       "1287 -0.018103 -0.017993 -0.017912 -0.017865 -0.017854 -0.017877 -0.017928  \n",
       "1288 -0.018390 -0.018273 -0.018189 -0.018138 -0.018122 -0.018142 -0.018194  \n",
       "1289 -0.018340 -0.018227 -0.018148 -0.018104 -0.018094 -0.018115 -0.018165  \n",
       "\n",
       "[1290 rows x 410 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.select_dtypes('float')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1955\n",
       "1       1969\n",
       "2       1974\n",
       "3       1976\n",
       "4       1996\n",
       "        ... \n",
       "1285    1942\n",
       "1286    1952\n",
       "1287    1962\n",
       "1288    1972\n",
       "1289    1982\n",
       "Name: year, Length: 1290, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['year']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomState(MT19937) at 0x7F51BD7F4740"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test split\n",
    "\n",
    "During this Project, we will generate statistical model with a random fraction of the dataset. The remainder will be retained to be used as test values to estimate the accuracy of the model and potentially detect overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the dataset into 70% training and 30% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest (RSCV)\n",
    "Implemented: \n",
    "- parameter distribution  \n",
    "- Train  \n",
    "- Test  \n",
    "- CV Results  \n",
    "- Optimal Model Parameters  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 1 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 2 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 3 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 4 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 5 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 6 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 7 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 8 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 9 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 10 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 11 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 12 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 13 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 14 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Execution time: 67.74892281293869 minutes\n"
     ]
    }
   ],
   "source": [
    "# RF Define the parameters for the CV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_predict as cvp\n",
    "from scipy.stats import randint\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "rf = RandomForestRegressor() # default criterion to evaluate the quality of the split is the ”squared_error”\n",
    "\n",
    "param_distribs = {'n_estimators': randint(low=3, high=150), # for hyperparameter with discrete values \n",
    "                  'min_samples_split': randint(low=2, high=20), \n",
    "                  'max_depth': randint(low=1, high=20), \n",
    "                  'min_samples_leaf': randint(low=1, high=10),\n",
    "                  }\n",
    "\n",
    "# loop the fitting with splits of the data\n",
    "rf_rscv_rmse1 = np.zeros((NoTrials, 1))\n",
    "rf_rscv_rmse2 = np.zeros((NoTrials, 1))\n",
    "\n",
    "for i in range(0, NoTrials):\n",
    "    print(f\"Trial {i} of {NoTrials}\")\n",
    "\n",
    "    # Split the data into 'nfolds' number of splits \n",
    "    inner_cv = KFold(n_splits=nfolds, shuffle=True, random_state=random_state)\n",
    "    outer_cv = KFold(n_splits=nfolds, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # define the RSCV object\n",
    "    rf_rscv = RandomizedSearchCV(\n",
    "        rf, # regressor\n",
    "        param_distributions=param_distribs, # hyperparameter space\n",
    "        n_iter=10, # \"Number of parameter settings that are sampled.\" [sklearn]\n",
    "        cv=inner_cv, # \"Determines the cross-validation splitting strategy\"[sklearn]\n",
    "        scoring=cv_scorer, \n",
    "        random_state=random_state, \n",
    "        verbose=1, \n",
    "        n_jobs=n_jobs)\n",
    "    \n",
    "    # fit the model on the Trainig Data\n",
    "    rf_rscv.fit(X_train, y_train)\n",
    "\n",
    "    # calculate the CV scores\n",
    "    rf_rscv_rmse1[i] = np.sqrt(-rf_rscv.best_score_)\n",
    "    y_pred_rf = cvp(rf_rscv, X_train, y_train, cv=outer_cv, n_jobs=n_jobs)\n",
    "    rf_rscv_rmse2[i] = np.sqrt(mean_squared_error(y_train, y_pred_rf))\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = (end_time - start_time)/60\n",
    "print(f\"Execution time: {execution_time} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal Parameters according to RSCV: {'max_depth': 19, 'min_samples_leaf': 3, 'min_samples_split': 7, 'n_estimators': 23}\n",
      "best score -14876.810753198622\n"
     ]
    }
   ],
   "source": [
    "print('optimal Parameters according to RSCV:', rf_rscv.best_params_)\n",
    "print('best score', rf_rscv.best_score_) # this returns the negative of the MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF with optimal parameters\n",
    "\n",
    "extract the best parameters and run the RF Regression with the full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal parameters\n",
    "rf_opt = RandomForestRegressor(**rf_rscv.best_params_)\n",
    "\n",
    "#fit the model\n",
    "rf_opt.fit(X_train, y_train)\n",
    "\n",
    "# predict the values for X_test\n",
    "y_pred_rf = rf_opt.predict(X_test)\n",
    "\n",
    "# calculate the error between y_test (true) and y predicted\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122.98601790347223"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLS (RSCV)\n",
    "Implemented:\n",
    "\n",
    "\n",
    "*TODO*\n",
    "\n",
    "- parameter distribution  \n",
    "- Train  \n",
    "- Test  \n",
    "- CV Results  \n",
    "- Optimal Model Parameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(387, 410)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The parameter search should be limited in regards to the numebr of components to keep:\n",
    "# \"Should be in [1, min(n_samples, n_features, n_targets)]\" sklearn\n",
    "\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 1 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 2 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 3 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 4 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 5 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 6 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 7 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 8 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 9 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 10 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 11 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 12 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 13 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 14 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Execution time: 3.6151899456977845 minutes\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters for the CV\n",
    "from sklearn import cross_decomposition\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "pls = cross_decomposition.PLSRegression()\n",
    "\n",
    "param_distribs = {'n_components': randint(low=1, high=90), #  should be in [1, min(n_samples, n_features, n_targets = 90)].\n",
    "                  'max_iter': randint(low=2, high=700), \n",
    "                  }\n",
    "\n",
    "# loop the fitting with splits of the data\n",
    "pls_rscv_rmse1 = np.zeros((NoTrials, 1))\n",
    "pls_rscv_rmse2 = np.zeros((NoTrials, 1))\n",
    "\n",
    "for i in range(0, NoTrials):\n",
    "    print(f\"Trial {i} of {NoTrials}\")\n",
    "\n",
    "    # Split the data into 'nfolds' number of splits \n",
    "    inner_cv = KFold(n_splits=nfolds, shuffle=True, random_state=random_state)\n",
    "    outer_cv = KFold(n_splits=nfolds, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # define the RSCV object\n",
    "    pls_rscv = RandomizedSearchCV(\n",
    "        pls, # regressor\n",
    "        param_distributions=param_distribs, # hyperparameter space\n",
    "        n_iter=10, # \"Number of parameter settings that are sampled.\" [sklearn]\n",
    "        cv=inner_cv, # \"Determines the cross-validation splitting strategy\"[sklearn]\n",
    "        scoring=cv_scorer, \n",
    "        random_state=random_state, \n",
    "        verbose=1, \n",
    "        n_jobs=n_jobs)\n",
    "    \n",
    "    # fit the model on the Trainig Data\n",
    "    pls_rscv.fit(X_train, y_train)\n",
    "\n",
    "    # calculate the CV scores\n",
    "    pls_rscv_rmse1[i] = np.sqrt(-pls_rscv.best_score_)\n",
    "    y_pred_pls = cvp(pls_rscv, X_train, y_train, cv=outer_cv, n_jobs=n_jobs)\n",
    "    pls_rscv_rmse2[i] = np.sqrt(mean_squared_error(y_train, y_pred_pls))\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = (end_time - start_time)/60\n",
    "print(f\"Execution time: {execution_time} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal Parameters according to RSCV: {'max_iter': 38, 'n_components': 30}\n",
      "best score -9864.388872329746\n"
     ]
    }
   ],
   "source": [
    "print('optimal Parameters according to RSCV:', pls_rscv.best_params_)\n",
    "print('best score' ,pls_rscv.best_score_) # this returns the negative of the MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLS with optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal parameters\n",
    "pls_opt = cross_decomposition.PLSRegression(**pls_rscv.best_params_)\n",
    "\n",
    "#fit the model\n",
    "pls_opt.fit(X_train, y_train)\n",
    "\n",
    "# predict the values for X_test\n",
    "\n",
    "y_pred_pls = pls_opt.predict(X_test)\n",
    "\n",
    "# calculate the error between y_test (true) and y predicted\n",
    "rmse_pls = np.sqrt(mean_squared_error(y_test, y_pred_pls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103.6372588328837"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_pls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KRR with RBF (RSCV)\n",
    "Implemented:\n",
    "\n",
    "- parameter distribution  \n",
    "- Train  \n",
    "- Test  \n",
    "- CV Results  \n",
    "- Optimal Model Parameters  \n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KRR with RBF \n",
    "\n",
    "# alpha: Regularization strength\n",
    "\n",
    "param_distribs = {\"alpha\": [1e0, 1e-1, 1e-2, 1e-3], \n",
    "                  \"gamma\": np.logspace(-2, 2, 7)}\n",
    "\n",
    "# param_distribs = {\"alpha\": np.logspace(0.0001, 0.1), \n",
    "#                  \"gamma\": np.logspace(0.0001, 0.1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-02, 4.64158883e-02, 2.15443469e-01, 1.00000000e+00,\n",
       "       4.64158883e+00, 2.15443469e+01, 1.00000000e+02])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-2, 2, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 1 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 2 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 3 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 4 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 5 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 6 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 7 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 8 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 9 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 10 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fitsFitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 11 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 12 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 13 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 14 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Execution time: 1.6823788285255432 minutes\n"
     ]
    }
   ],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge as KRR\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# loop the fitting with splits of the data\n",
    "krr_rscv_rmse1 = np.zeros((NoTrials, 1))\n",
    "krr_rscv_rmse2 = np.zeros((NoTrials, 1))\n",
    "\n",
    "for i in range(0, NoTrials):\n",
    "    print(f\"Trial {i} of {NoTrials}\")\n",
    "\n",
    "    # Split the data into 'nfolds' number of splits \n",
    "    inner_cv = KFold(n_splits=nfolds, shuffle=True, random_state=random_state)\n",
    "    outer_cv = KFold(n_splits=nfolds, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # define the RSCV object\n",
    "    krr_rscv = RandomizedSearchCV(\n",
    "        KRR(kernel='rbf'), # regressor\n",
    "        param_distributions=param_distribs, # hyperparameter space\n",
    "        n_iter=10, # \"Number of parameter settings that are sampled.\" [sklearn]\n",
    "        cv=inner_cv, # \"Determines the cross-validation splitting strategy\"[sklearn]\n",
    "        scoring=cv_scorer, \n",
    "        random_state=random_state, \n",
    "        verbose=1, \n",
    "        n_jobs=n_jobs)\n",
    "    \n",
    "    # fit the model on the Trainig Data\n",
    "    krr_rscv.fit(X_train, y_train)\n",
    "\n",
    "    # calculate the CV scores\n",
    "    krr_rscv_rmse1[i] = np.sqrt(-krr_rscv.best_score_)\n",
    "    y_pred_krr = cvp(krr_rscv, X_train, y_train, cv=outer_cv, n_jobs=n_jobs)\n",
    "    krr_rscv_rmse2[i] = np.sqrt(mean_squared_error(y_train, y_pred_krr))\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = (end_time - start_time)/ 60\n",
    "print(f\"Execution time: {execution_time} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal Parameters according to RSCV: {'gamma': 4.641588833612777, 'alpha': 0.001}\n",
      "best score -10934.320041126219\n"
     ]
    }
   ],
   "source": [
    "print('optimal Parameters according to RSCV:', krr_rscv.best_params_)\n",
    "print('best score' ,krr_rscv.best_score_) # this returns the negative of the MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KRR (rbf) with optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal parameters\n",
    "krr_opt = KRR(**krr_rscv.best_params_)\n",
    "\n",
    "#fit the model\n",
    "krr_opt.fit(X_train, y_train)\n",
    "\n",
    "# predict the values for X_test\n",
    "\n",
    "y_pred_krr = krr_opt.predict(X_test)\n",
    "\n",
    "# calculate the error between y_test (true) and y predicted\n",
    "rmse_krr = np.sqrt(mean_squared_error(y_test, y_pred_krr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129.7497505300415"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_krr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP (RSCV)\n",
    "\n",
    "This Method, the multi-layer perceptron creates a neural network, where neurons are organized in three or more layers (1 input-, n hidden-, and 1 output-layer). The MLP is based on a threshold logic unit (TLU, sometimes linear threshold unit LTU). A TLU recieves input from its connections and calculates 'weights' from the sum of all inputs and calculates a step function. Common step functions are the *Heaviside step function* or *sign function*. \n",
    "\n",
    "To compute the outputs of a single fully connnected layer the following eq. can be used \n",
    "\n",
    "(citation: A. Géron, Hands-on machine learning with Scikit-Learn and TensorFlow concepts, tools, and techniques to build intelligent systems, 2nd ed. O’Reilly Media, Inc., 2019. p.283)\n",
    "‌\n",
    "\n",
    "$$h_{W,b}(X) = \\phi(WX + b)$$\n",
    "\n",
    "Implemented: \n",
    "\n",
    "- parameter distribution  \n",
    "- Train  \n",
    "- Test  \n",
    "- CV Results  \n",
    "- Optimal Model Parameters \n",
    "\n",
    "*TODO* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter Distribution for mlp\n",
    "\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "param_distribs = {\"hidden_layer_sizes\": randint(low=50, high=200), # number of neurons in each layer\n",
    "                  \"activation\": ['identity', 'logistic', 'tanh', 'relu'],\n",
    "                  \"solver\": ['lbfgs','sgd', 'adam'],\n",
    "                  'alpha': uniform(loc=0.0001, scale=0.1),\n",
    "                  'early_stopping': [True, False],  \n",
    "                  'validation_fraction': uniform(loc=0.1, scale=0.1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 1 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n",
      "10 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 476, in _fit\n",
      "    self._fit_stochastic(\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 660, in _fit_stochastic\n",
      "    self._update_no_improvement_count(early_stopping, X_val, y_val)\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 708, in _update_no_improvement_count\n",
      "    self.validation_scores_.append(self._score(X_val, y_val))\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 1611, in _score\n",
      "    return r2_score(y, y_pred)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/metrics/_regression.py\", line 1180, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/metrics/_regression.py\", line 104, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1049, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 126, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 175, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [              nan   -75907.81752893   -38698.69306986   -16357.13955505\n",
      " -2864516.6204705    -38923.85197485   -16630.9211326    -38779.97571637\n",
      " -2606573.46825922   -14695.28953907]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 2 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 3 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 4 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 5 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n",
      "20 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 496, in _fit\n",
      "    raise ValueError(\n",
      "ValueError: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [              nan  -738411.67131767 -2719752.11843374               nan\n",
      "   -16232.96299707   -38846.825306   -1061303.90250531 -2650371.46026474\n",
      "   -16399.56692943   -38981.93925196]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 6 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 7 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 8 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n",
      "20 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 476, in _fit\n",
      "    self._fit_stochastic(\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 660, in _fit_stochastic\n",
      "    self._update_no_improvement_count(early_stopping, X_val, y_val)\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 708, in _update_no_improvement_count\n",
      "    self.validation_scores_.append(self._score(X_val, y_val))\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 1611, in _score\n",
      "    return r2_score(y, y_pred)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/metrics/_regression.py\", line 1180, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/metrics/_regression.py\", line 104, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1049, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 126, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 175, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [  -39320.67450863   -38896.50643552 -2742019.03582517   -91284.32792565\n",
      "   -16683.4792963  -2478186.42893928   -16210.4352319                nan\n",
      "   -15361.45763992               nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 9 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n",
      "10 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 496, in _fit\n",
      "    raise ValueError(\n",
      "ValueError: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [  -15925.16954815   -64945.23162086 -2685445.52823264   -15266.61998735\n",
      "               nan   -38788.6201067  -2505295.42838692   -15495.14466548\n",
      "   -38861.03622542 -2634834.28110373]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 10 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n",
      "10 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 476, in _fit\n",
      "    self._fit_stochastic(\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 660, in _fit_stochastic\n",
      "    self._update_no_improvement_count(early_stopping, X_val, y_val)\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 708, in _update_no_improvement_count\n",
      "    self.validation_scores_.append(self._score(X_val, y_val))\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 1611, in _score\n",
      "    return r2_score(y, y_pred)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/metrics/_regression.py\", line 1180, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/metrics/_regression.py\", line 104, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1049, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 126, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 175, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [  -16545.593821   -2833798.96669593   -39025.86523755   -39308.16158721\n",
      "   -39250.9986785  -2334443.64816785   -15620.39322698   -38668.77155859\n",
      "               nan   -16346.19724457]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 11 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n",
      "10 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 496, in _fit\n",
      "    raise ValueError(\n",
      "ValueError: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [-2479814.99139      -38686.32473436   -38730.98574185   -13894.30595266\n",
      "               nan   -15326.20577345   -15089.11570218   -38863.35061172\n",
      "  -293879.72366729 -2809216.58605538]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 12 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n",
      "20 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 476, in _fit\n",
      "    self._fit_stochastic(\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 660, in _fit_stochastic\n",
      "    self._update_no_improvement_count(early_stopping, X_val, y_val)\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 708, in _update_no_improvement_count\n",
      "    self.validation_scores_.append(self._score(X_val, y_val))\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 1611, in _score\n",
      "    return r2_score(y, y_pred)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/metrics/_regression.py\", line 1180, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/metrics/_regression.py\", line 104, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1049, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 126, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 175, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [  -39217.71659515 -1114851.08478691   -14048.12854879               nan\n",
      "   -15779.26250401   -38699.04191389   -16202.29112649               nan\n",
      "   -16077.9721213   -778256.02341286]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 13 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 14 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Execution time: 63.976682802041374 minutes\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor as MLP\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# loop the fitting with splits of the data\n",
    "mlp_rscv_rmse1 = np.zeros((NoTrials, 1))\n",
    "mlp_rscv_rmse2 = np.zeros((NoTrials, 1))\n",
    "\n",
    "for i in range(0, NoTrials):\n",
    "    print(f\"Trial {i} of {NoTrials}\")\n",
    "\n",
    "    # Split the data into 'nfolds' number of splits \n",
    "    inner_cv = KFold(n_splits=nfolds, shuffle=True, random_state=random_state)\n",
    "    outer_cv = KFold(n_splits=nfolds, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # define the RSCV object\n",
    "    mlp_rscv = RandomizedSearchCV(\n",
    "        MLP(), # regressor\n",
    "        param_distributions=param_distribs, # hyperparameter space\n",
    "        n_iter=10, # \"Number of parameter settings that are sampled.\" [sklearn]\n",
    "        cv=inner_cv, # \"Determines the cross-validation splitting strategy\"[sklearn]\n",
    "        scoring=cv_scorer, \n",
    "        random_state=random_state, \n",
    "        verbose=1, \n",
    "        n_jobs=n_jobs)\n",
    "    \n",
    "    # fit the model on the Trainig Data\n",
    "    mlp_rscv.fit(X_train, y_train)\n",
    "\n",
    "    # calculate the CV scores\n",
    "    mlp_rscv_rmse1[i] = np.sqrt(-mlp_rscv.best_score_)\n",
    "    y_pred_mlp = cvp(mlp_rscv, X_train, y_train, cv=outer_cv, n_jobs=n_jobs)\n",
    "    mlp_rscv_rmse2[i] = np.sqrt(mean_squared_error(y_train, y_pred_mlp))\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = (end_time - start_time)/ 60\n",
    "print(f\"Execution time: {execution_time} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal Parameters according to RSCV: {'activation': 'tanh', 'alpha': 0.018092607452333143, 'early_stopping': False, 'hidden_layer_sizes': 93, 'solver': 'lbfgs', 'validation_fraction': 0.14112525964015027}\n",
      "best score -13800.961982239276\n"
     ]
    }
   ],
   "source": [
    "print('optimal Parameters according to RSCV:', mlp_rscv.best_params_)\n",
    "print('best score' ,mlp_rscv.best_score_) # this returns the negative of the MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal parameters\n",
    "mlp_opt = MLP(**mlp_rscv.best_params_)\n",
    "\n",
    "#fit the model\n",
    "mlp_opt.fit(X_train, y_train)\n",
    "\n",
    "# predict the values for X_test\n",
    "y_pred_mlp = mlp_opt.predict(X_test)\n",
    "\n",
    "# calculate the error between y_test (true) and y predicted\n",
    "rmse_mlp = np.sqrt(mean_squared_error(y_test, y_pred_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115.61234301860294"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost (RSCV)\n",
    "\n",
    "Implemented:\n",
    "\n",
    "- import\n",
    "\n",
    "*TODO*\n",
    "\n",
    "\n",
    "- parameter distribution  \n",
    "- Train  \n",
    "- Test  \n",
    "- CV Results  \n",
    "- Optimal Model Parameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.3'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost\n",
    "xgboost.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### transform the data into the XGBoost data class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details see [datacamp](https://www.datacamp.com/tutorial/xgboost-in-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regression matrices\n",
    "dtrain_reg = xgboost.DMatrix(X_train, y_train)\n",
    "dtest_reg = xgboost.DMatrix(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the objective\n",
    "\n",
    "XGBoost will be used here for a regression problem, with the objective to minimize the squared error of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"objective\": \"reg:squarederror\", \n",
    "          \"tree_method\": \"hist\"} # \"gpu_hist\" for gpu only, set to 'hist' if on cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:158.91235\tvalidation-rmse:170.96301\n",
      "[20]\ttrain-rmse:23.83772\tvalidation-rmse:124.03000\n",
      "[40]\ttrain-rmse:8.38947\tvalidation-rmse:124.03466\n",
      "[60]\ttrain-rmse:3.18431\tvalidation-rmse:123.78980\n",
      "[71]\ttrain-rmse:1.87073\tvalidation-rmse:123.80743\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameters\n",
    "\n",
    "n = 500 # number of rounds\n",
    "evals = [(dtrain_reg, \"train\"), (dtest_reg, \"validation\")] # specify the data for evaluation\n",
    "\n",
    "model = xgboost.train(\n",
    "   params=params,\n",
    "   dtrain=dtrain_reg,\n",
    "   num_boost_round=n,\n",
    "   evals=evals,\n",
    "   verbose_eval = 20, \n",
    "   early_stopping_rounds=20,\n",
    ")\n",
    "\n",
    "# [60]\ttrain-rmse:3.18431\tvalidation-rmse:123.78980\n",
    "# [71]\ttrain-rmse:1.87073\tvalidation-rmse:123.80743"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>157.790979</td>\n",
       "      <td>1.473083</td>\n",
       "      <td>170.071095</td>\n",
       "      <td>9.402711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129.446537</td>\n",
       "      <td>2.077011</td>\n",
       "      <td>154.529123</td>\n",
       "      <td>11.302401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109.085485</td>\n",
       "      <td>2.194860</td>\n",
       "      <td>143.455057</td>\n",
       "      <td>10.752623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93.441676</td>\n",
       "      <td>2.404388</td>\n",
       "      <td>136.020008</td>\n",
       "      <td>9.874314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81.071116</td>\n",
       "      <td>2.945638</td>\n",
       "      <td>133.587989</td>\n",
       "      <td>9.806164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "0       157.790979        1.473083      170.071095       9.402711\n",
       "1       129.446537        2.077011      154.529123      11.302401\n",
       "2       109.085485        2.194860      143.455057      10.752623\n",
       "3        93.441676        2.404388      136.020008       9.874314\n",
       "4        81.071116        2.945638      133.587989       9.806164"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 1000\n",
    "\n",
    "results = xgboost.cv(\n",
    "   params,\n",
    "   dtrain_reg,\n",
    "   num_boost_round=n,\n",
    "   nfold=5,\n",
    "   early_stopping_rounds=20\n",
    ")\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121.57590195197679"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rmse = results['test-rmse-mean'].min()\n",
    "\n",
    "best_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acessing the xgboost eval metrics via sklearn\n",
    "\n",
    "from tutorial of [xgboost](https://xgboost.readthedocs.io/en/latest/python/examples/sklearn_evals_result.html#demo-for-accessing-the-xgboost-eval-metrics-by-using-sklearn-interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regression matrices\n",
    "dtrain_reg = xgboost.DMatrix(X_train, y_train)\n",
    "dtest_reg = xgboost.DMatrix(X_test, y_test)\n",
    "\n",
    "params = {\"objective\": [\"reg:squarederror\"], \n",
    "          \"tree_method\": [\"hist\"]}\n",
    "\n",
    "XGB = xgboost.XGBModel(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 1 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 2 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 3 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 4 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 5 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 6 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 7 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 8 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 9 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 10 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Trial 11 of 15\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# calculate the CV scores\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     xgb_rscv_rmse1[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m-\u001b[39mxgb_rscv\u001b[38;5;241m.\u001b[39mbest_score_)\n\u001b[0;32m---> 40\u001b[0m     y_pred_xgb \u001b[38;5;241m=\u001b[39m \u001b[43mcvp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxgb_rscv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mouter_cv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     xgb_rscv_rmse2[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mean_squared_error(y_train, y_pred_xgb))\n\u001b[1;32m     43\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:1293\u001b[0m, in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m-> 1293\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_predict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1306\u001b[0m inv_test_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mlen\u001b[39m(test_indices), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m   1307\u001b[0m inv_test_indices[test_indices] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(test_indices))\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/joblib/parallel.py:1703\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1701\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[1;32m   1702\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 1703\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_abort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1704\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1706\u001b[0m     \u001b[38;5;66;03m# Store the unconsumed tasks and terminate the workers if necessary\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/joblib/parallel.py:1614\u001b[0m, in \u001b[0;36mParallel._abort\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborted \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabort_everything\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m   1610\u001b[0m     \u001b[38;5;66;03m# If the backend is managed externally we need to make sure\u001b[39;00m\n\u001b[1;32m   1611\u001b[0m     \u001b[38;5;66;03m# to leave it in a working state to allow for future jobs\u001b[39;00m\n\u001b[1;32m   1612\u001b[0m     \u001b[38;5;66;03m# scheduling.\u001b[39;00m\n\u001b[1;32m   1613\u001b[0m     ensure_ready \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_managed_backend\n\u001b[0;32m-> 1614\u001b[0m     \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabort_everything\u001b[49m\u001b[43m(\u001b[49m\u001b[43mensure_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_ready\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1615\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/joblib/_parallel_backends.py:620\u001b[0m, in \u001b[0;36mLokyBackend.abort_everything\u001b[0;34m(self, ensure_ready)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mabort_everything\u001b[39m(\u001b[38;5;28mself\u001b[39m, ensure_ready\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    618\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Shutdown the workers and restart a new one with the same parameters\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_workers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkill_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ensure_ready:\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/joblib/executor.py:75\u001b[0m, in \u001b[0;36mMemmappingExecutor.terminate\u001b[0;34m(self, kill_workers)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mterminate\u001b[39m(\u001b[38;5;28mself\u001b[39m, kill_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkill_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkill_workers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m# When workers are killed in a brutal manner, they cannot execute the\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# finalizer of their shared memmaps. The refcount of those memmaps may\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# be off by an unknown number, so instead of decref'ing them, we force\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;66;03m# with allow_non_empty=True but if we can't, it will be clean up later\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;66;03m# on by the resource_tracker.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_submit_resize_lock:\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:1303\u001b[0m, in \u001b[0;36mProcessPoolExecutor.shutdown\u001b[0;34m(self, wait, kill_workers)\u001b[0m\n\u001b[1;32m   1299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m executor_manager_thread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m wait:\n\u001b[1;32m   1300\u001b[0m     \u001b[38;5;66;03m# This locks avoids concurrent join if the interpreter\u001b[39;00m\n\u001b[1;32m   1301\u001b[0m     \u001b[38;5;66;03m# is shutting down.\u001b[39;00m\n\u001b[1;32m   1302\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _global_shutdown_lock:\n\u001b[0;32m-> 1303\u001b[0m         \u001b[43mexecutor_manager_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m         _threads_wakeups\u001b[38;5;241m.\u001b[39mpop(executor_manager_thread, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;66;03m# To reduce the risk of opening too many files, remove references to\u001b[39;00m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;66;03m# objects that use file descriptors.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/threading.py:1147\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1147\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/threading.py:1167\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1168\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1169\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "start_time = time.time()\n",
    "# Instantiate the regressor\n",
    "XGB = XGBRegressor()\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_estimators\": randint(100,500),\n",
    "    \"max_depth\": randint(3,100)\n",
    "}\n",
    "\n",
    "\n",
    "# loop the fitting with splits of the data\n",
    "xgb_rscv_rmse1 = np.zeros((NoTrials, 1))\n",
    "xgb_rscv_rmse2 = np.zeros((NoTrials, 1))\n",
    "\n",
    "for i in range(0, NoTrials):\n",
    "    print(f\"Trial {i} of {NoTrials}\")\n",
    "\n",
    "    # Split the data into 'nfolds' number of splits \n",
    "    inner_cv = KFold(n_splits=nfolds, shuffle=True, random_state=random_state)\n",
    "    outer_cv = KFold(n_splits=nfolds, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # define the RSCV object\n",
    "    xgb_rscv = RandomizedSearchCV(\n",
    "        XGB, # regressor\n",
    "        param_distributions = param_distribs, # hyperparameter space\n",
    "        n_iter = 10, # \"Number of parameter settings that are sampled.\" [sklearn]\n",
    "        cv = inner_cv, # \"Determines the cross-validation splitting strategy\" [sklearn]\n",
    "        scoring = cv_scorer, \n",
    "        random_state = random_state, \n",
    "        verbose = 1, \n",
    "        n_jobs = n_jobs)\n",
    "    \n",
    "    # fit the model on the Trainig Data\n",
    "    xgb_rscv.fit(X_train, y_train)\n",
    "\n",
    "    # calculate the CV scores\n",
    "    xgb_rscv_rmse1[i] = np.sqrt(-xgb_rscv.best_score_)\n",
    "    y_pred_xgb = cvp(xgb_rscv, X_train, y_train, cv=outer_cv, n_jobs=n_jobs)\n",
    "    xgb_rscv_rmse2[i] = np.sqrt(mean_squared_error(y_train, y_pred_xgb))\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = (end_time - start_time)/ 60\n",
    "print(f\"Execution time: {execution_time} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal Parameters according to RSCV: {'max_depth': 5, 'n_estimators': 393}\n",
      "best score -13534.912770700568\n"
     ]
    }
   ],
   "source": [
    "print('optimal Parameters according to RSCV:', xgb_rscv.best_params_)\n",
    "print('best score' ,xgb_rscv.best_score_) # this returns the negative of the MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal parameters\n",
    "best_params = xgb_rscv.best_params_\n",
    "\n",
    "xgb_opt = XGBRegressor(**xgb_rscv.best_params_)\n",
    "\n",
    "#fit the model\n",
    "xgb_opt.fit(X_train, y_train)\n",
    "\n",
    "# predict the values for X_test\n",
    "y_pred_xgb = xgb_opt.predict(X_test)\n",
    "\n",
    "# calculate the error between y_test (true) and y predicted\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124.21650265526222"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram-based Gradient Boosting Regression Tree\n",
    "\n",
    "*TODO*\n",
    "- parameter distribution\n",
    "- Train  \n",
    "- Test  \n",
    "- CV Results  \n",
    "- Optimal Model Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 of 15\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_search.py:318: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Trial 1 of 15\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_search.py:318: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Trial 2 of 15\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_search.py:318: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Trial 3 of 15\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_search.py:318: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Trial 4 of 15\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_search.py:318: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Trial 5 of 15\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_search.py:318: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Trial 6 of 15\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_search.py:318: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Trial 7 of 15\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_search.py:318: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Trial 8 of 15\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_search.py:318: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Trial 9 of 15\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_search.py:318: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Trial 10 of 15\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_search.py:318: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Trial 11 of 15\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_search.py:318: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Trial 12 of 15\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_search.py:318: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Trial 13 of 15\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_search.py:318: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Trial 14 of 15\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhwn.ac.at/202375/.conda/envs/thesis/lib/python3.12/site-packages/sklearn/model_selection/_search.py:318: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Execution time: 438.2999840815862 minutes\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor as HGB\n",
    "\n",
    "# Define parameters for HGB\n",
    "#param_distribs = {\n",
    "#    'learning_rate':randint(low=0.001,high=1),\n",
    "#    'max_iter':randint(low=5,high=250), \n",
    "#     'max_leaf_nodes': randint(low=2,high=50, scale = 1)\n",
    "#                  }\n",
    "param_distribs = {'max_iter': [5,10], \n",
    "                  'max_leaf_nodes': [15,31,40],\n",
    "                  }\n",
    "\n",
    "# loop the fitting with splits of the data\n",
    "hgb_rscv_rmse1 = np.zeros((NoTrials, 1))\n",
    "hgb_rscv_rmse2 = np.zeros((NoTrials, 1))\n",
    "\n",
    "for i in range(0, NoTrials):\n",
    "    print(f\"Trial {i} of {NoTrials}\")\n",
    "\n",
    "    # Split the data into 'nfolds' number of splits \n",
    "    inner_cv = KFold(n_splits=nfolds, shuffle=True, random_state=random_state)\n",
    "    outer_cv = KFold(n_splits=nfolds, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # define the RSCV object\n",
    "    hgb_rscv =RandomizedSearchCV(\n",
    "        HGB(), # regressor\n",
    "        param_distributions=param_distribs, # hyperparameter space\n",
    "        n_iter=10, # \"Number of parameter settings that are sampled.\" [sklearn]\n",
    "        cv=inner_cv, # \"Determines the cross-validation splitting strategy\"[sklearn]\n",
    "        scoring=cv_scorer, \n",
    "        random_state=random_state, \n",
    "        verbose=1, \n",
    "        n_jobs=n_jobs)\n",
    "    \n",
    "    # fit the model on the Trainig Data\n",
    "    hgb_rscv.fit(X_train, y_train)\n",
    "\n",
    "    # calculate the CV scores\n",
    "    hgb_rscv_rmse1[i] = np.sqrt(-hgb_rscv.best_score_)\n",
    "    y_pred_hgb = cvp(hgb_rscv, X_train, y_train, cv=outer_cv, n_jobs=n_jobs)\n",
    "    hgb_rscv_rmse2[i] = np.sqrt(mean_squared_error(y_train, y_pred_hgb))\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = (end_time - start_time)/60\n",
    "print(f\"Execution time: {execution_time} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal Parameters according to RSCV: {'max_leaf_nodes': 31, 'max_iter': 10}\n",
      "best score -19639.775208577506\n"
     ]
    }
   ],
   "source": [
    "print('optimal Parameters according to RSCV:', hgb_rscv.best_params_)\n",
    "print('best score' ,hgb_rscv.best_score_) # this returns the negative of the MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HGB with optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141.15222233482842"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimal parameters\n",
    "hgb_opt = HGB(**hgb_rscv.best_params_)\n",
    "\n",
    "#fit the model\n",
    "hgb_opt.fit(X_train, y_train)\n",
    "\n",
    "# predict the values for X_test\n",
    "\n",
    "y_pred_hgb = hgb_opt.predict(X_test)\n",
    "\n",
    "# calculate the error between y_test (true) and y predicted\n",
    "rmse_hgb = np.sqrt(mean_squared_error(y_test, y_pred_hgb))\n",
    "rmse_hgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Computational Considerations \n",
    "\n",
    "# Define the current models: \n",
    "\n",
    "model_list = [\"rf_opt\", \"pls_opt\", \"krr_opt\", \"xgb_opt\", \"hgb_opt\"]\n",
    "\n",
    "# write the models to memory: \n",
    "if save_model == True:\n",
    "    for i in model_list: \n",
    "        # Extract model name\n",
    "        #model_name = \n",
    "        model_name = i + i.__class__.__name__\n",
    "        # Construct a filepath\n",
    "        model_filepath = MODEL_PATH + f\"/{model_name}.pkl\"\n",
    "        # Save the model\n",
    "        joblib.dump(i, model_filepath)\n",
    "else:\n",
    "    print(\"Testrun, no model is written\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the models from memory\n",
    "\n",
    "for model in model_list:  \n",
    "    model_name = model.__class__.__name__  \n",
    "    model_filepath = MODEL_PATH + f\"/{model_name}.pkl\"  \n",
    "    model = joblib.load(model_filepath)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality Control\n",
    "\n",
    "In this section the goal is to document the packages which where used during the execution of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "System:\n",
      "    python: 3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:38:13) [GCC 12.3.0]\n",
      "executable: /home/fhwn.ac.at/202375/.conda/envs/thesis/bin/python\n",
      "   machine: Linux-5.15.0-101-generic-x86_64-with-glibc2.31\n",
      "\n",
      "Python dependencies:\n",
      "      sklearn: 1.4.2\n",
      "          pip: 24.0\n",
      "   setuptools: 69.5.1\n",
      "        numpy: 1.26.4\n",
      "        scipy: 1.13.0\n",
      "       Cython: None\n",
      "       pandas: 2.2.2\n",
      "   matplotlib: 3.8.4\n",
      "       joblib: 1.4.2\n",
      "threadpoolctl: 3.5.0\n",
      "\n",
      "Built with OpenMP: True\n",
      "\n",
      "threadpoolctl info:\n",
      "       user_api: blas\n",
      "   internal_api: openblas\n",
      "    num_threads: 80\n",
      "         prefix: libopenblas\n",
      "       filepath: /home/fhwn.ac.at/202375/.conda/envs/thesis/lib/libopenblasp-r0.3.27.so\n",
      "        version: 0.3.27\n",
      "threading_layer: pthreads\n",
      "   architecture: SkylakeX\n",
      "\n",
      "       user_api: openmp\n",
      "   internal_api: openmp\n",
      "    num_threads: 80\n",
      "         prefix: libgomp\n",
      "       filepath: /home/fhwn.ac.at/202375/.conda/envs/thesis/lib/libgomp.so.1.0.0\n",
      "        version: None\n"
     ]
    }
   ],
   "source": [
    "## Package informations\n",
    "from sklearn import show_versions\n",
    "show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 597.9394542932511 minutes\n"
     ]
    }
   ],
   "source": [
    "nb_end_time = time.time()\n",
    "nb_execution_time = (nb_end_time - nb_start_time) / 60\n",
    "print(f\"Execution time: {nb_execution_time} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook 03_1_modeling_rscv.ipynb to html\n",
      "[NbConvertApp] Writing 604666 bytes to results/03_modeling_results/03_1_modeling_rscv_2024-05-10.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# Get the current date\n",
    "now = datetime.datetime.now()\n",
    "date = now.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Define the notebook name, output name, and output directory\n",
    "try:\n",
    "    nb_filepath = __vsc_ipynb_file__ # works for Visual Studio Code\n",
    "    notebook_name = nb_filepath.split('/')[-1]\n",
    "except:\n",
    "    print('Please enter the notebook name manually')\n",
    "    pass\n",
    "# notebook_name = '03_1_modeling_rscv.ipynb'\n",
    "\n",
    "output_name = f\"{notebook_name.split('.')[0]}_{date}.html\"\n",
    "\n",
    "output_directory = './results/03_modeling_results/'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Specify the full output path\n",
    "full_output_path = os.path.join(output_directory, output_name)\n",
    "\n",
    "# Convert notebook to html with specified output name and path\n",
    "subprocess.call(['jupyter', 'nbconvert', '--to', 'html', notebook_name, '--output', full_output_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/fhwn.ac.at/202375/Thesis')]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals()['_dh'][0] # notebook path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to convert the notebook to HTML\n",
    "def convert_notebook_to_html(notebook_name, output_name, RESULTS_PATH=RESULTS_PATH):\n",
    "    full_output_path = os.path.join(RESULTS_PATH, output_name)\n",
    "        # Use subprocess to call the jupyter nbconvert command\n",
    "    subprocess.call(['jupyter', 'nbconvert', '--to', 'html', 'notebook_name','--output', 'output_name', '--output-dir', 'RESULTS_PATH'])\n",
    "    \n",
    "    # Optionally, rename the output file if needed\n",
    "    # os.rename(notebook_name.split('.')[0] + '.html', full_output_path)\n",
    "\n",
    "# Wait for a short period to ensure all cells have finished executing\n",
    "time.sleep(3) # Adjust the sleep duration as needed\n",
    "\n",
    "# Convert the notebook to HTML\n",
    "convert_notebook_to_html(notebook_name, output_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
